<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-US"><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://hoff2.dev/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hoff2.dev/" rel="alternate" type="text/html" hreflang="en-US" /><updated>2021-05-05T00:40:08+00:00</updated><id>https://hoff2.dev/feed.xml</id><title type="html">Chuck Hoffman</title><subtitle>Another programmer blog, lucky you.</subtitle><entry><title type="html">SQL and NoSQL</title><link href="https://hoff2.dev/2020-12-14-sql-and-nosql/" rel="alternate" type="text/html" title="SQL and NoSQL" /><published>2020-12-14T00:00:00+00:00</published><updated>2020-12-14T00:00:00+00:00</updated><id>https://hoff2.dev/sql-and-nosql</id><content type="html" xml:base="https://hoff2.dev/2020-12-14-sql-and-nosql/">&lt;blockquote&gt;
  &lt;p&gt;Recently I was given some job interview questions to prepare for. I decided
to try writing my thoughts on the subjects. I had fun with it so I decided to
clean them up a bit and make them blog posts. One thing I noticed was that
when writing, I didn’t have so much a name let alone a mental picture of a
hypothetical senior engineer I’d be interviewing with and seemed instead to
be writing for the recruiter I’d been in contact with as intended audience. I
was explaining concepts less to impress someone and more to actually teach.
Therefore I hope these posts are informative to someone.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Q: When might you want to use a NoSQL database instead of SQL?&lt;/p&gt;

&lt;p&gt;Generally speaking, a database is any store of data and the means to find and
use what is in it, which may include a query language such as SQL. The file
system(s) used by the operating system on your computer is also a database, and
you might even think of file names/paths as part of a query language for it. A
file system has metadata for keeping track of where the bits that are called by
a given filename in a given folder are physically kept on the disk (or whatever
storage medium you might be abstractly referring to as a “disk”), so as to help
the software to find, use, add, and modify files in ways a user might request.&lt;/p&gt;

&lt;p&gt;These same factors also define other kinds of databases: a way of organizing
data in some storage medium; facilities for accessing, calculating from, adding
to, and modifying it; and metadata (such as indexes) to support these
facilities. Various database architectures have different ways of implementing
these things that can support different logical models of data access to varying
degrees of speed and space efficiency.&lt;/p&gt;

&lt;p&gt;The term “NoSQL” is interesting because I suspect that it may be highlighting
the wrong variable and thereby misleading. The defining factors of NoSQL
databases as opposed to what users of this term mean by SQL databases seems to
me to have more to do with the underlying architecture and features of a
database engine, than with the SQL query language itself. But SQL is closely
correlated to what are called relational databases, a model which has dominated
the field of databases, in the sense of which most people think of the term
“database”, for a number of years now.&lt;/p&gt;

&lt;p&gt;Relational databases provide a logical model of data arranged in tables, the
rows being data records, containing fields (arranged in columns) that hold the
component data of the records. There are keys to uniquely identify particular
records, foreign keys to express &lt;em&gt;relationships&lt;/em&gt; between records, be they in the
same table or different, and indexes to help the system locate records by keys.
It’s all fairly intuitive to folks who know their way around spreadsheets and
also quite logically flexible. Relational databases almost universally offer an
SQL interface, but I have also seen SQL-like languages offered for other kinds
of data stores such as ksqldb for Kafka, and proprietary specialized dialects
like this one thing Salesforce has that I can’t remember the name of right now.
They have become the default choices of database to back most applications that
need something they can’t get from, say, sticking stuff in files; to the degree
that the term “database” has become nearly synonymous with them, and the
occupation of “database administrator” likewise synonymous with someone skilled
at working with SQL, various extensions of SQL, and relational database
solutions in general or specific.&lt;/p&gt;

&lt;p&gt;Relational databases have been so dominant for so long for good reason. They are
good general-purpose databases and a lot of work over a long time has gone into
making them good. They give you facilities to be able to do just about anything
with the data they contain that you might conceivably dream up, almost as
quickly as you can dream it up. You can put lots of data in an SQL database and
get a lot out functionality of it easily.  Right now I’d still say if you’re
building a new product, there’s almost no reason not to at least start off with
one of these databases even if you’re keeping your options open in the longer
term. Free and open-source solutions like PostgreSQL are competitive with
commercial offerings like Microsoft SQL or Oracle, and at small scale and/or
early stages of a product you can even go with something easy and
low-maintenance like MySQL or SQLite. You can run them on your own laptop and do
all the nasty things to them you could ever want to try as you develop a
product.&lt;/p&gt;

&lt;p&gt;But yeah, this is the hegemony that birthed the NoSQL meme. Some tech companies
were getting big doing some innovative stuff and found themselves reaching
performance and scale needs that relational databases weren’t up for. Being
pretty good at a lot of things sometimes leaves you coming up short on very
specific things, especially things that were rarer when the system was initially
designed. Everything’s a trade-off. Demand increased for distributed and
parallel computing to handle high load, and relational databases often weren’t
the best at scaling out. Replication exists but it’s pretty meh, and sharding is
helpful for some things but can be difficult to get right. Other kinds of
databases needed to be found or built to meet new needs.&lt;/p&gt;

&lt;p&gt;The NoSQL movement may be little more than a recognition of these conditions.
Its effect has seemed to be to bring attention to other kinds of database
systems. A caching system can get by with less features for structuring data so
long as it can access it quickly. A reporting system would have more need for
pulling a lot of data at once and flexibility in structuring it, but place less
importance on the data being up-to-the-millisecond consistent across your
enterprise. Through message- and event-driven system design techniques, one can
even represent the same information in multiple different databases to support
different applications. NoSQL was mostly about recognizing that we had more
choices than we might have realized.&lt;/p&gt;

&lt;p&gt;So ultimately, the answer to the question of when you might want to use a SQL
database versus a NoSQL one comes down to the old “consultants’ answer” of “it
depends.” But what I hope I have been able to get across is a good sense of what
kinds of things it might depend &lt;em&gt;on&lt;/em&gt;. There exist now a variety of database
solutions besides SQL/relational, all focused on being good at different things.
The question isn’t so much SQL versus NoSQL, as it is a choice among a variety
of databases of which SQL is but one subcategory.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Got a tech question you’d like me to write on? Send it to hoff2 at HEY dot
com.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="databases" /><category term="SQL" /><category term="NoSQL" /><summary type="html">Recently I was given some job interview questions to prepare for. I decided to try writing my thoughts on the subjects. I had fun with it so I decided to clean them up a bit and make them blog posts. One thing I noticed was that when writing, I didn’t have so much a name let alone a mental picture of a hypothetical senior engineer I’d be interviewing with and seemed instead to be writing for the recruiter I’d been in contact with as intended audience. I was explaining concepts less to impress someone and more to actually teach. Therefore I hope these posts are informative to someone. Q: When might you want to use a NoSQL database instead of SQL? Generally speaking, a database is any store of data and the means to find and use what is in it, which may include a query language such as SQL. The file system(s) used by the operating system on your computer is also a database, and you might even think of file names/paths as part of a query language for it. A file system has metadata for keeping track of where the bits that are called by a given filename in a given folder are physically kept on the disk (or whatever storage medium you might be abstractly referring to as a “disk”), so as to help the software to find, use, add, and modify files in ways a user might request. These same factors also define other kinds of databases: a way of organizing data in some storage medium; facilities for accessing, calculating from, adding to, and modifying it; and metadata (such as indexes) to support these facilities. Various database architectures have different ways of implementing these things that can support different logical models of data access to varying degrees of speed and space efficiency. The term “NoSQL” is interesting because I suspect that it may be highlighting the wrong variable and thereby misleading. The defining factors of NoSQL databases as opposed to what users of this term mean by SQL databases seems to me to have more to do with the underlying architecture and features of a database engine, than with the SQL query language itself. But SQL is closely correlated to what are called relational databases, a model which has dominated the field of databases, in the sense of which most people think of the term “database”, for a number of years now. Relational databases provide a logical model of data arranged in tables, the rows being data records, containing fields (arranged in columns) that hold the component data of the records. There are keys to uniquely identify particular records, foreign keys to express relationships between records, be they in the same table or different, and indexes to help the system locate records by keys. It’s all fairly intuitive to folks who know their way around spreadsheets and also quite logically flexible. Relational databases almost universally offer an SQL interface, but I have also seen SQL-like languages offered for other kinds of data stores such as ksqldb for Kafka, and proprietary specialized dialects like this one thing Salesforce has that I can’t remember the name of right now. They have become the default choices of database to back most applications that need something they can’t get from, say, sticking stuff in files; to the degree that the term “database” has become nearly synonymous with them, and the occupation of “database administrator” likewise synonymous with someone skilled at working with SQL, various extensions of SQL, and relational database solutions in general or specific. Relational databases have been so dominant for so long for good reason. They are good general-purpose databases and a lot of work over a long time has gone into making them good. They give you facilities to be able to do just about anything with the data they contain that you might conceivably dream up, almost as quickly as you can dream it up. You can put lots of data in an SQL database and get a lot out functionality of it easily. Right now I’d still say if you’re building a new product, there’s almost no reason not to at least start off with one of these databases even if you’re keeping your options open in the longer term. Free and open-source solutions like PostgreSQL are competitive with commercial offerings like Microsoft SQL or Oracle, and at small scale and/or early stages of a product you can even go with something easy and low-maintenance like MySQL or SQLite. You can run them on your own laptop and do all the nasty things to them you could ever want to try as you develop a product. But yeah, this is the hegemony that birthed the NoSQL meme. Some tech companies were getting big doing some innovative stuff and found themselves reaching performance and scale needs that relational databases weren’t up for. Being pretty good at a lot of things sometimes leaves you coming up short on very specific things, especially things that were rarer when the system was initially designed. Everything’s a trade-off. Demand increased for distributed and parallel computing to handle high load, and relational databases often weren’t the best at scaling out. Replication exists but it’s pretty meh, and sharding is helpful for some things but can be difficult to get right. Other kinds of databases needed to be found or built to meet new needs. The NoSQL movement may be little more than a recognition of these conditions. Its effect has seemed to be to bring attention to other kinds of database systems. A caching system can get by with less features for structuring data so long as it can access it quickly. A reporting system would have more need for pulling a lot of data at once and flexibility in structuring it, but place less importance on the data being up-to-the-millisecond consistent across your enterprise. Through message- and event-driven system design techniques, one can even represent the same information in multiple different databases to support different applications. NoSQL was mostly about recognizing that we had more choices than we might have realized. So ultimately, the answer to the question of when you might want to use a SQL database versus a NoSQL one comes down to the old “consultants’ answer” of “it depends.” But what I hope I have been able to get across is a good sense of what kinds of things it might depend on. There exist now a variety of database solutions besides SQL/relational, all focused on being good at different things. The question isn’t so much SQL versus NoSQL, as it is a choice among a variety of databases of which SQL is but one subcategory. Got a tech question you’d like me to write on? Send it to hoff2 at HEY dot com.</summary></entry><entry><title type="html">Notes on Dependency Injection</title><link href="https://hoff2.dev/2020-12-11-dependency-injection/" rel="alternate" type="text/html" title="Notes on Dependency Injection" /><published>2020-12-11T00:00:00+00:00</published><updated>2020-12-11T00:00:00+00:00</updated><id>https://hoff2.dev/dependency-injection</id><content type="html" xml:base="https://hoff2.dev/2020-12-11-dependency-injection/">&lt;blockquote&gt;
  &lt;p&gt;Recently I was given some job interview questions to prepare for. I decided
to try writing my thoughts on the subjects. I had fun with it so I decided to
clean them up a bit and make them blog posts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Q: “Can you explain what inversion of control or dependency injection is and
what benefit it provides?”&lt;/p&gt;

&lt;p&gt;Dependency Injection/Inversion Of Control is a concept that came up in the
theory around object-oriented programming some years back. The general idea is,
you have some procedure in your program that needs to get at some data values,
system resources, and other procedures to be able to do its job. When or how you
specify all these things are a matter of how you design your code. Given an OO
programming language, this procedure is probably a method on some class, so some
things may have been specified to the objects’ constructor; others might be
given as arguments to the method call. Or they may have been calculated,
provided through setter methods, or constructed from other things in the
meantime. The constructor is itself a method with parameters, whose job is to
give you a new instance of this class, and those parameters can technically be
anything or nothing, just like any other method. In between the constructor,
other setup of state done beforehand within the class scope, and parameters,
eventually the method has everything it needs if it is to work.&lt;/p&gt;

&lt;p&gt;You find that in purely Functional Programming circles you rarely hear
dependency injection talked about, let alone stressed about, the way it has in
OO programming. At a basic level one could say that this because in these
languages everything is made out of pure functions, so technically the only way
to get things into a function is through its parameters, so you don’t have all
these choices to weigh. This might sound like a nightmare if you care much about
functions having a lot of parameters. But then that’s what closures are for,
&lt;a href=&quot;/2019-10-06-functional-fun/&quot;&gt;which are how FP “does” objects&lt;/a&gt;, as it turns out,
and out of them you also get currying and monads.&lt;/p&gt;

&lt;p&gt;In the early days of object orientation, as its dominance in industry was new,
many design principles, patterns, and practices we’ve since come to take for
granted were yet to grow. Much of the field was still thinking in Procedural or
Structured Programming terms and was still figuring out how to use the tool of
OO &lt;em&gt;well&lt;/em&gt;. This is normal. I’ve since seen it happen with Actors and
Microservices and arguably even Functional Programming, with three-quarters of a
century of history behind it, is still lacking in some of this area.&lt;/p&gt;

&lt;p&gt;Object Oriented programming languages’ native facility for invoking an object is
to call a class constructor. Often there is a special language keyword to do
this, such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;new&lt;/code&gt;. If you need some kind of object, this is supposedly how you
get it. If that constructor needs some other objects though, what does it do?
It’s not entirely unreasonable to think that that constructor would go off and
call other constructors and so people did that sort of thing a lot.&lt;/p&gt;

&lt;p&gt;However, this started to lead to some nasty smells. One would find oneself
writing constructors that need a whole lot of parameters, even if it’s just so
it can pass most of those parameters on to other constructors; writing out the
very long calls to those many-parametered constructors, “threading through”
parameters from one class to another to another, and probably getting parameters
in the wrong order several times and other prosaic human errors that happen when
you’re dealing with complicated code. To make matters worse, you ended up with
classes and methods that are bound to specific context-dependent things in your
application and don’t easily generalize to other circumstances; OO’s promise of
reusable code fails to come through. This got especially hairy with the growing
popularity of unit testing and test-driven development – you would try to set
up a test suite for some class in your code and find that you had to build out a
whole hairball of stuff just to set up an instance to test on, and then someone
would tell you that if you were doing that then it wasn’t true “unit” testing,
and you’d throw up your hands and go back to your old ways.&lt;/p&gt;

&lt;p&gt;Eventually some genius remembered that we can pass &lt;em&gt;objects&lt;/em&gt; along as parameters
too, so we could just build those downstream dependencies ahead of time and pass
them in. “Injecting” your dependencies’ dependencies into them, instead of just
letting your dependencies build all their own dependencies, this “inversion” of
the “control” over dependencies, passed for enough of a mindshift to make it a
buzzword.&lt;/p&gt;

&lt;p&gt;Indeed, it was considered such a mindshift that people decided they couldn’t
handle the responsibility themselves and needed to have frameworks called
Dependency Injection “Containers” to do the heavy lifting. It was &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;new&lt;/code&gt;’s fault
for letting us call it wherever we want; instead we should let this container
use reflection and/or big XML configuration files to find all the right things
to plug into all the constructors for us so that wherever we wrote methods,
whatever they needed could just be there. After all, “dependency resolution” was
something of a solved problem in the realm of the &lt;em&gt;installation&lt;/em&gt; of software. We
had package systems for Linux distros, as well as those to manage library code
our projects depend on. They build a data representation of what depends on
what, and what other whats those whats depend on, on down to the whats that
don’t depend on any other whats, and go and find the right versions of the right
things and put them where they’re needed.&lt;/p&gt;

&lt;p&gt;DI/IoC Containers caught on widely in the worlds of enterprise Java and C#. This
way of handling dependencies within a project had apparent time-saving benefits
due to what it lets you avoid thinking about, against the tradeoff that it gives
you an incentive to not think about those things. When you write a class you
simply stick on the annotation that plugs it into the DI container, and now you
don’t have to think much about how to structure dependencies.&lt;/p&gt;

&lt;p&gt;In practice, how this often plays out is that if you’re coding in some new
functionality and want some dependency the class doesn’t already have in scope,
you just add it to the constructor and keep going. Heck, often the IDE will just
do it for you with a keyboard shortcut. You don’t care how long that constructor
signature gets because you never have to write a call to it anyway. The
constructor’s signatures get bigger and bigger and the import lists at the top
of the files get longer and longer and your unit tests have to set up more and
more mocks but because all this grew a little at a time you’ve stopped noticing
it, like the people on Hoarders who are immune to the smell of their own homes.
Without applying some design discipline, at the end of the day, this state of
affairs is not only hardly better than just cramming a lot of stuff into a
global namespace, it’s worse because it fills your code with boilerplate, and
your classes lose all cohesion or real meaning beyond being arbitrary bags of
dependencies. What’s a separation of concerns?&lt;/p&gt;

&lt;p&gt;In Scala’s early days of aiming to be a “better Java”, they tried to improve on
this with a scoping feature called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;implicit&lt;/code&gt; that ended up replicating similar
problems in the form of a certain crime against humanity called the Cake
Pattern. Implicits came to be widely hated, though maybe not always fairly; they
ended up being repurposed to build out an FP concept called typeclasses, which
sound awesome until you realize they’re kind of just interfaces.&lt;/p&gt;

&lt;p&gt;DI/IoC containers continue to be popular, especially in the context of
opinionated-architecture application frameworks in popular enterprise
platforms/languages, and I’m able to work with them. When it’s up to me,
however, I prefer to use basic constructor- or setter-based DI methods in a
manner influenced by things like hexagonal/ports-and-adapters or DCI
architectures. Even then, messes get made.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Got a programming topic you’d like me to rant on? Send it to hoff2 at HEY dot
com.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="Dependency Injection" /><summary type="html">Recently I was given some job interview questions to prepare for. I decided to try writing my thoughts on the subjects. I had fun with it so I decided to clean them up a bit and make them blog posts. Q: “Can you explain what inversion of control or dependency injection is and what benefit it provides?” Dependency Injection/Inversion Of Control is a concept that came up in the theory around object-oriented programming some years back. The general idea is, you have some procedure in your program that needs to get at some data values, system resources, and other procedures to be able to do its job. When or how you specify all these things are a matter of how you design your code. Given an OO programming language, this procedure is probably a method on some class, so some things may have been specified to the objects’ constructor; others might be given as arguments to the method call. Or they may have been calculated, provided through setter methods, or constructed from other things in the meantime. The constructor is itself a method with parameters, whose job is to give you a new instance of this class, and those parameters can technically be anything or nothing, just like any other method. In between the constructor, other setup of state done beforehand within the class scope, and parameters, eventually the method has everything it needs if it is to work. You find that in purely Functional Programming circles you rarely hear dependency injection talked about, let alone stressed about, the way it has in OO programming. At a basic level one could say that this because in these languages everything is made out of pure functions, so technically the only way to get things into a function is through its parameters, so you don’t have all these choices to weigh. This might sound like a nightmare if you care much about functions having a lot of parameters. But then that’s what closures are for, which are how FP “does” objects, as it turns out, and out of them you also get currying and monads. In the early days of object orientation, as its dominance in industry was new, many design principles, patterns, and practices we’ve since come to take for granted were yet to grow. Much of the field was still thinking in Procedural or Structured Programming terms and was still figuring out how to use the tool of OO well. This is normal. I’ve since seen it happen with Actors and Microservices and arguably even Functional Programming, with three-quarters of a century of history behind it, is still lacking in some of this area. Object Oriented programming languages’ native facility for invoking an object is to call a class constructor. Often there is a special language keyword to do this, such as new. If you need some kind of object, this is supposedly how you get it. If that constructor needs some other objects though, what does it do? It’s not entirely unreasonable to think that that constructor would go off and call other constructors and so people did that sort of thing a lot. However, this started to lead to some nasty smells. One would find oneself writing constructors that need a whole lot of parameters, even if it’s just so it can pass most of those parameters on to other constructors; writing out the very long calls to those many-parametered constructors, “threading through” parameters from one class to another to another, and probably getting parameters in the wrong order several times and other prosaic human errors that happen when you’re dealing with complicated code. To make matters worse, you ended up with classes and methods that are bound to specific context-dependent things in your application and don’t easily generalize to other circumstances; OO’s promise of reusable code fails to come through. This got especially hairy with the growing popularity of unit testing and test-driven development – you would try to set up a test suite for some class in your code and find that you had to build out a whole hairball of stuff just to set up an instance to test on, and then someone would tell you that if you were doing that then it wasn’t true “unit” testing, and you’d throw up your hands and go back to your old ways. Eventually some genius remembered that we can pass objects along as parameters too, so we could just build those downstream dependencies ahead of time and pass them in. “Injecting” your dependencies’ dependencies into them, instead of just letting your dependencies build all their own dependencies, this “inversion” of the “control” over dependencies, passed for enough of a mindshift to make it a buzzword. Indeed, it was considered such a mindshift that people decided they couldn’t handle the responsibility themselves and needed to have frameworks called Dependency Injection “Containers” to do the heavy lifting. It was new’s fault for letting us call it wherever we want; instead we should let this container use reflection and/or big XML configuration files to find all the right things to plug into all the constructors for us so that wherever we wrote methods, whatever they needed could just be there. After all, “dependency resolution” was something of a solved problem in the realm of the installation of software. We had package systems for Linux distros, as well as those to manage library code our projects depend on. They build a data representation of what depends on what, and what other whats those whats depend on, on down to the whats that don’t depend on any other whats, and go and find the right versions of the right things and put them where they’re needed. DI/IoC Containers caught on widely in the worlds of enterprise Java and C#. This way of handling dependencies within a project had apparent time-saving benefits due to what it lets you avoid thinking about, against the tradeoff that it gives you an incentive to not think about those things. When you write a class you simply stick on the annotation that plugs it into the DI container, and now you don’t have to think much about how to structure dependencies. In practice, how this often plays out is that if you’re coding in some new functionality and want some dependency the class doesn’t already have in scope, you just add it to the constructor and keep going. Heck, often the IDE will just do it for you with a keyboard shortcut. You don’t care how long that constructor signature gets because you never have to write a call to it anyway. The constructor’s signatures get bigger and bigger and the import lists at the top of the files get longer and longer and your unit tests have to set up more and more mocks but because all this grew a little at a time you’ve stopped noticing it, like the people on Hoarders who are immune to the smell of their own homes. Without applying some design discipline, at the end of the day, this state of affairs is not only hardly better than just cramming a lot of stuff into a global namespace, it’s worse because it fills your code with boilerplate, and your classes lose all cohesion or real meaning beyond being arbitrary bags of dependencies. What’s a separation of concerns? In Scala’s early days of aiming to be a “better Java”, they tried to improve on this with a scoping feature called implicit that ended up replicating similar problems in the form of a certain crime against humanity called the Cake Pattern. Implicits came to be widely hated, though maybe not always fairly; they ended up being repurposed to build out an FP concept called typeclasses, which sound awesome until you realize they’re kind of just interfaces. DI/IoC containers continue to be popular, especially in the context of opinionated-architecture application frameworks in popular enterprise platforms/languages, and I’m able to work with them. When it’s up to me, however, I prefer to use basic constructor- or setter-based DI methods in a manner influenced by things like hexagonal/ports-and-adapters or DCI architectures. Even then, messes get made. Got a programming topic you’d like me to rant on? Send it to hoff2 at HEY dot com.</summary></entry><entry><title type="html">Hello again</title><link href="https://hoff2.dev/2020-12-05-hello-again/" rel="alternate" type="text/html" title="Hello again" /><published>2020-12-05T00:00:00+00:00</published><updated>2020-12-05T00:00:00+00:00</updated><id>https://hoff2.dev/hello-again</id><content type="html" xml:base="https://hoff2.dev/2020-12-05-hello-again/">&lt;p&gt;Once upon a time I blogged a lot. Then I kind of got over myself. I have strong opinions weakly held so I don’t feel a need to evangelize them much. I may try to put in an article here every so often to just say how I am and how things are going in general though. I guess it doesn’t hurt to sort of reintroduce yourself each time you post if it’s infrequent. It’s just your new home page anyway. Not like I have followers.&lt;/p&gt;

&lt;p&gt;I’m a software developer in Iowa. I’m about agile and TDD and pairing and collaboration and collective learning and stuff. I’m less about specific like, frameworks or programming languages or platforms or “tech stacks”. A lot of underlying ideas are repeated and refined over the years in successive products and you start to kind of automatically pattern-match new ones as they crop up. Or at least I do. I’m not sure everyone has this experience. Learning builds upon previous learning in a network model though so the potential connections grow at a higher order than the number of concepts they might connect. Humans are pattern matching machines and we kind of prime ourselves for these experiences if we can. I’m cynical on the cult of smart, though.&lt;/p&gt;

&lt;p&gt;Naturally, I’m writing for something to do at the moment because I don’t have current work. Maybe you could hire me. I’m pretty ok. Check out the about page and anything else you can find from the menus up top.&lt;/p&gt;

&lt;p&gt;thank.&lt;/p&gt;</content><author><name></name></author><summary type="html">Once upon a time I blogged a lot. Then I kind of got over myself. I have strong opinions weakly held so I don’t feel a need to evangelize them much. I may try to put in an article here every so often to just say how I am and how things are going in general though. I guess it doesn’t hurt to sort of reintroduce yourself each time you post if it’s infrequent. It’s just your new home page anyway. Not like I have followers. I’m a software developer in Iowa. I’m about agile and TDD and pairing and collaboration and collective learning and stuff. I’m less about specific like, frameworks or programming languages or platforms or “tech stacks”. A lot of underlying ideas are repeated and refined over the years in successive products and you start to kind of automatically pattern-match new ones as they crop up. Or at least I do. I’m not sure everyone has this experience. Learning builds upon previous learning in a network model though so the potential connections grow at a higher order than the number of concepts they might connect. Humans are pattern matching machines and we kind of prime ourselves for these experiences if we can. I’m cynical on the cult of smart, though. Naturally, I’m writing for something to do at the moment because I don’t have current work. Maybe you could hire me. I’m pretty ok. Check out the about page and anything else you can find from the menus up top. thank.</summary></entry><entry><title type="html">Wesley Willis, a tribute</title><link href="https://hoff2.dev/2020-08-04-wesley-willis-a-tribute/" rel="alternate" type="text/html" title="Wesley Willis, a tribute" /><published>2020-08-04T00:00:00+00:00</published><updated>2020-08-04T00:00:00+00:00</updated><id>https://hoff2.dev/wesley-willis-a-tribute</id><content type="html" xml:base="https://hoff2.dev/2020-08-04-wesley-willis-a-tribute/">&lt;blockquote&gt;
  &lt;p&gt;The following was written June 1, 2020 and originally posted to mental
health-related internal chat rooms where I worked at the time&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Yesterday was the last day of Mental Health Awareness Month.&lt;/p&gt;

&lt;p&gt;Yesterday would also have been &lt;a href=&quot;https://en.wikipedia.org/wiki/Wesley_Willis&quot;&gt;Wesley
Willis’s&lt;/a&gt; 57th birthday.&lt;/p&gt;

&lt;p&gt;If you’re from the Alternative Nation Generation, you may remember Wesley Willis
as something of a curiosity, maybe a bit of a joke and a distastefully
exploitative one at that, the sort of thing that would never pass in today’s
social climate and should probably be left where we left it. A mentally ill
street musician from Chicago (to most, with the word “musician” enclosed in
irony-quotes) whom seemingly somebody allowed to start releasing albums and
playing clubs for amusements’ sake, sparking a weird 1990s fad with a rather
long tail on it.&lt;/p&gt;

&lt;p&gt;The truth has a lot more to it though, and today I want to talk about what that
story obscures and misses that Wesley Willis fans and friends-of-friends like
myself knew. I want to shine a light on the man Wesley Willis was. The man who
faced adversity after adversity and never lost the beautiful soul that inspired
friends, brought joy to mass numbers of music nerds, and ultimately made it
possible for Wesley Willis to make way for himself to live authentically in a
world all but designed specifically against him. Whose sincerity and enthusiasm
made him an effortlessly savvy self-promoter and brought him opportunities and
agency denied to so many others like him. Who worked hard at doing what he both
loved and needed and radiated love as he did it. It would be to no one’s
surprise his time on Earth was short, but he made the absolute most of it.&lt;/p&gt;

&lt;p&gt;Two documentary films have been made about Mr. Willis, and of the two, one still
has a bit of that snicker-at-the-freak smell on it. The one I’d like to invite
people to check out if they can find it, &lt;em&gt;Wesley Willis’s Joyrides&lt;/em&gt;, focuses on
his life story and personal accounts from his closest friends and also gives
space to his no less substantial visual arts career. While many have found
Wesley Willis’s compositional methods primitive and maddeningly repetitive,
there is much depth to be found for those willing to grant time and attention to
his oeuvre. In this moment I would particularly like to highlight those songs in
which Wesley Willis dealt frankly with his experiences with mental illness:
“Chronic Schizophrenia” and “Outburst” from “Greatest Hits Vol. 1” are easy to
find but there are many more.&lt;/p&gt;

&lt;p&gt;On June 1 2020, I can say that not only is the world a bit cooler place for
having had Wesley Willis in it, but fortunate and downright lucky that Wesley
Willis never met the fate of George Floyd or so many other black men and
neurodivergent black men throughout our country’s history.&lt;/p&gt;

&lt;p&gt;RIP Wesley Willis, you are still loved like a milkshake.&lt;/p&gt;</content><author><name></name></author><category term="Wesley Willis" /><category term="mental health" /><summary type="html">The following was written June 1, 2020 and originally posted to mental health-related internal chat rooms where I worked at the time Yesterday was the last day of Mental Health Awareness Month. Yesterday would also have been Wesley Willis’s 57th birthday. If you’re from the Alternative Nation Generation, you may remember Wesley Willis as something of a curiosity, maybe a bit of a joke and a distastefully exploitative one at that, the sort of thing that would never pass in today’s social climate and should probably be left where we left it. A mentally ill street musician from Chicago (to most, with the word “musician” enclosed in irony-quotes) whom seemingly somebody allowed to start releasing albums and playing clubs for amusements’ sake, sparking a weird 1990s fad with a rather long tail on it. The truth has a lot more to it though, and today I want to talk about what that story obscures and misses that Wesley Willis fans and friends-of-friends like myself knew. I want to shine a light on the man Wesley Willis was. The man who faced adversity after adversity and never lost the beautiful soul that inspired friends, brought joy to mass numbers of music nerds, and ultimately made it possible for Wesley Willis to make way for himself to live authentically in a world all but designed specifically against him. Whose sincerity and enthusiasm made him an effortlessly savvy self-promoter and brought him opportunities and agency denied to so many others like him. Who worked hard at doing what he both loved and needed and radiated love as he did it. It would be to no one’s surprise his time on Earth was short, but he made the absolute most of it. Two documentary films have been made about Mr. Willis, and of the two, one still has a bit of that snicker-at-the-freak smell on it. The one I’d like to invite people to check out if they can find it, Wesley Willis’s Joyrides, focuses on his life story and personal accounts from his closest friends and also gives space to his no less substantial visual arts career. While many have found Wesley Willis’s compositional methods primitive and maddeningly repetitive, there is much depth to be found for those willing to grant time and attention to his oeuvre. In this moment I would particularly like to highlight those songs in which Wesley Willis dealt frankly with his experiences with mental illness: “Chronic Schizophrenia” and “Outburst” from “Greatest Hits Vol. 1” are easy to find but there are many more. On June 1 2020, I can say that not only is the world a bit cooler place for having had Wesley Willis in it, but fortunate and downright lucky that Wesley Willis never met the fate of George Floyd or so many other black men and neurodivergent black men throughout our country’s history. RIP Wesley Willis, you are still loved like a milkshake.</summary></entry><entry><title type="html">Strange Times Are Here</title><link href="https://hoff2.dev/2020-06-28-strange-times/" rel="alternate" type="text/html" title="Strange Times Are Here" /><published>2020-06-28T00:00:00+00:00</published><updated>2020-06-28T00:00:00+00:00</updated><id>https://hoff2.dev/strange-times</id><content type="html" xml:base="https://hoff2.dev/2020-06-28-strange-times/">&lt;p&gt;It’s been weird times lately for me, and for many others. If it hasn’t been
weird times for you, that must be some nice bubble you’re living in.&lt;/p&gt;

&lt;p&gt;I write this on a Sunday. Friday was my last day as an employee of The Des
Moines Forge Of Pillar Part Of Industry X.0 By Accenture. Fortunately I’m a
techbro and had a job offer the same day at a slightly higher salary. I don’t
think I’m going to take it.&lt;/p&gt;

&lt;p&gt;I happened to rewatch &lt;a href=&quot;https://www.imdb.com/title/tt3715406&quot;&gt;&lt;em&gt;Atari: Game Over&lt;/em&gt;&lt;/a&gt;
yesterday. In it, Howard Warshaw, developer of not only the ill-fated &lt;em&gt;E.T.&lt;/em&gt;
game but also such unquestionable classics as &lt;em&gt;Yar’s Revenge&lt;/em&gt;, reflected on how
his brief experience at Atari kind of ruined him for subsequent job prospects.
Made him expect better, want more, be less willing to compromise for the sake of
going along with the typical corporate environment. Not just because of the wild
party culture of Atari in the early 1980s but just as much because of the
heights of creative achievement that he and his co-workers reached together,
enabled by that openness in which they could bring their whole selves to work.&lt;/p&gt;

&lt;p&gt;When I came on at Pillar, it was in the process of being acquired by Accenture.
Accenture is the biggest corporation you never heard of. It employs literally
half a million people globally in all sorts of consulting and professional
services sectors. I knew of this, it was brought up in my interviews. I seem to
have a knack for coming into companies at these moments; my hiring at Banno, my
previous job, came at much the same juncture of their acquisition by Jack Henry
&amp;amp; Associates. And just like with Banno, the message that went out in Pillar was
that what the acquirer saw in the acquiree, the thing to which they attributed
the smaller company’s success that made it such an attractive acquisition
target, was its great culture, and that the big company’s intentions were to
learn from that and spread the lessons out to the larger company and with that
we were going to rock the world and it was going to be great.&lt;/p&gt;

&lt;p&gt;I’ve had a fraught relationship with employment all my legally-employable life.
The workplace was always just an even more repressive corner of an already
repressive world where I never quite belonged and suffered because of it, yet if
I didn’t find a way to slot myself into it, I would never be able to support
myself or a family. Pillar brought me out of the shell I’d built around myself
since I was a child, showed me my viewpoint was valid and valued in a way I
didn’t realize was possible. It took time for me to adjust and really begin to
open up, and I still feel like that process was interrupted in the middle, but I
am so overwhelmingly grateful to the people I worked alongside at the Forge that
helped that happen. It was a culture that delighted in being eccentric and that
spirit made us powerful and because of it we did awesome work. Pillar showed me
that I could be seen as more than just a human resource or a code monkey, that I
could be valued as a fully three-dimensional human being with all my flaws and
foibles and ambitions and silly jokes and wild ideas and nerdy interests.&lt;/p&gt;

&lt;p&gt;A week ago Friday though, Accenture told me something very different. Even after
all the apparently sincere and ground-breaking diversity and inclusion rhetoric
I’d heard, and what I took to be so many refreshingly bullshit-free statements
from CEO Julie Sweet, ultimately the message Accenture gave me was that I was
expendable: that literally some opaque process running in some cloud, triggered
by a fluctuation in a stock price or some such thing, could go and query an
employee database according to some algorithm, based off data like how many of
my work hours were directly billable to an already-won client, and by those
results could decide my professional fate, and that that was just totally normal
and the way things are done. Because that is evidently the world we are in now.&lt;/p&gt;

&lt;p&gt;And this may be what sucks the most now, is that, after Pillar, I don’t think I
can bring myself to settle for anything less… but what more, really, is out
there?&lt;/p&gt;

&lt;p&gt;Last Fall, I had the great honor, made possible by Accenture even, to be paid a
normal work day’s salary to be a guest lecturer for Hour Of Code, which is to
say that I along with several of my Forge co-workers spent a day helping to
guide public-school classrooms full of middle-school kids through some fun
coding exercises, where they could learn a little about what I do for a living.
One of the biggest things I was struck by and took away from that day was how
much more diverse those classrooms were from the rooms I typically spent a
workday in. To be slightly flippant about it, there were actually Black kids
there. And Hispanic kids. There was a Muslim girl (I’m assuming a little bit
here – she was brown-skinned and had a hijab on) who was joyously competing
with her Black friend next to her for who could complete the exercises quicker.
I remember thinking that if I’m in a position to influence hiring decisions in
ten years or so I sure hope these kids apply. And there were also kids that were
totally not into it, who thought all this techie stuff was bullshit, like the
Black girl who aspired to be a journalist, and I saw her point of view as no
less valid, because kids like her are used to seeing white dudes with glasses
like me doing this stuff, not people like them, and also because journalism is
totally important and we need it, and yet, we’re talking about language here,
which is all code really is, and even if you don’t make software your career,
understanding how it works is only going to be more crucial to your success in
this society going forward. I didn’t quite have the guts to say what I really
wanted to say, because I wasn’t the real teacher and it wasn’t my class. But
that was the beginnings of some notions in my head that I have higher purposes
to serve than just building another accounts-payable system.&lt;/p&gt;

&lt;p&gt;I don’t know what my future holds but I don’t think I’m likely to just take
another plain old tech job. The kind of thing I really want to do involves
sharing the joy of creativity that comes with my profession and helping young
people find their way into it that might otherwise give it up before they get
the chance; because I nearly did too, and that’s a whole other story. Pillar was
the first place I worked that tried to truly treat that kind of ambition as part
of the job, and whatever your company is, if you can’t get down with that, I
don’t think I can fuck with you anymore.&lt;/p&gt;

&lt;p&gt;Fortunately, I have maybe a couple months worth of financial cushion in which to
try to sort this all out. That’s not a privilege I ever had before.&lt;/p&gt;

&lt;p&gt;Like I said at the top of this rant, these are weird times. Hunter S. Thompson
is famously credited with saying, “When the going gets weird, the weird turn
pro.” I’ve been weird my whole life and this is my time to shine.&lt;/p&gt;</content><author><name></name></author><category term="career" /><category term="tech" /><summary type="html">It’s been weird times lately for me, and for many others. If it hasn’t been weird times for you, that must be some nice bubble you’re living in. I write this on a Sunday. Friday was my last day as an employee of The Des Moines Forge Of Pillar Part Of Industry X.0 By Accenture. Fortunately I’m a techbro and had a job offer the same day at a slightly higher salary. I don’t think I’m going to take it. I happened to rewatch Atari: Game Over yesterday. In it, Howard Warshaw, developer of not only the ill-fated E.T. game but also such unquestionable classics as Yar’s Revenge, reflected on how his brief experience at Atari kind of ruined him for subsequent job prospects. Made him expect better, want more, be less willing to compromise for the sake of going along with the typical corporate environment. Not just because of the wild party culture of Atari in the early 1980s but just as much because of the heights of creative achievement that he and his co-workers reached together, enabled by that openness in which they could bring their whole selves to work. When I came on at Pillar, it was in the process of being acquired by Accenture. Accenture is the biggest corporation you never heard of. It employs literally half a million people globally in all sorts of consulting and professional services sectors. I knew of this, it was brought up in my interviews. I seem to have a knack for coming into companies at these moments; my hiring at Banno, my previous job, came at much the same juncture of their acquisition by Jack Henry &amp;amp; Associates. And just like with Banno, the message that went out in Pillar was that what the acquirer saw in the acquiree, the thing to which they attributed the smaller company’s success that made it such an attractive acquisition target, was its great culture, and that the big company’s intentions were to learn from that and spread the lessons out to the larger company and with that we were going to rock the world and it was going to be great. I’ve had a fraught relationship with employment all my legally-employable life. The workplace was always just an even more repressive corner of an already repressive world where I never quite belonged and suffered because of it, yet if I didn’t find a way to slot myself into it, I would never be able to support myself or a family. Pillar brought me out of the shell I’d built around myself since I was a child, showed me my viewpoint was valid and valued in a way I didn’t realize was possible. It took time for me to adjust and really begin to open up, and I still feel like that process was interrupted in the middle, but I am so overwhelmingly grateful to the people I worked alongside at the Forge that helped that happen. It was a culture that delighted in being eccentric and that spirit made us powerful and because of it we did awesome work. Pillar showed me that I could be seen as more than just a human resource or a code monkey, that I could be valued as a fully three-dimensional human being with all my flaws and foibles and ambitions and silly jokes and wild ideas and nerdy interests. A week ago Friday though, Accenture told me something very different. Even after all the apparently sincere and ground-breaking diversity and inclusion rhetoric I’d heard, and what I took to be so many refreshingly bullshit-free statements from CEO Julie Sweet, ultimately the message Accenture gave me was that I was expendable: that literally some opaque process running in some cloud, triggered by a fluctuation in a stock price or some such thing, could go and query an employee database according to some algorithm, based off data like how many of my work hours were directly billable to an already-won client, and by those results could decide my professional fate, and that that was just totally normal and the way things are done. Because that is evidently the world we are in now. And this may be what sucks the most now, is that, after Pillar, I don’t think I can bring myself to settle for anything less… but what more, really, is out there? Last Fall, I had the great honor, made possible by Accenture even, to be paid a normal work day’s salary to be a guest lecturer for Hour Of Code, which is to say that I along with several of my Forge co-workers spent a day helping to guide public-school classrooms full of middle-school kids through some fun coding exercises, where they could learn a little about what I do for a living. One of the biggest things I was struck by and took away from that day was how much more diverse those classrooms were from the rooms I typically spent a workday in. To be slightly flippant about it, there were actually Black kids there. And Hispanic kids. There was a Muslim girl (I’m assuming a little bit here – she was brown-skinned and had a hijab on) who was joyously competing with her Black friend next to her for who could complete the exercises quicker. I remember thinking that if I’m in a position to influence hiring decisions in ten years or so I sure hope these kids apply. And there were also kids that were totally not into it, who thought all this techie stuff was bullshit, like the Black girl who aspired to be a journalist, and I saw her point of view as no less valid, because kids like her are used to seeing white dudes with glasses like me doing this stuff, not people like them, and also because journalism is totally important and we need it, and yet, we’re talking about language here, which is all code really is, and even if you don’t make software your career, understanding how it works is only going to be more crucial to your success in this society going forward. I didn’t quite have the guts to say what I really wanted to say, because I wasn’t the real teacher and it wasn’t my class. But that was the beginnings of some notions in my head that I have higher purposes to serve than just building another accounts-payable system. I don’t know what my future holds but I don’t think I’m likely to just take another plain old tech job. The kind of thing I really want to do involves sharing the joy of creativity that comes with my profession and helping young people find their way into it that might otherwise give it up before they get the chance; because I nearly did too, and that’s a whole other story. Pillar was the first place I worked that tried to truly treat that kind of ambition as part of the job, and whatever your company is, if you can’t get down with that, I don’t think I can fuck with you anymore. Fortunately, I have maybe a couple months worth of financial cushion in which to try to sort this all out. That’s not a privilege I ever had before. Like I said at the top of this rant, these are weird times. Hunter S. Thompson is famously credited with saying, “When the going gets weird, the weird turn pro.” I’ve been weird my whole life and this is my time to shine.</summary></entry><entry><title type="html">A fun tidbit of functional programming</title><link href="https://hoff2.dev/2019-10-06-functional-fun/" rel="alternate" type="text/html" title="A fun tidbit of functional programming" /><published>2019-10-06T00:00:00+00:00</published><updated>2019-10-06T00:00:00+00:00</updated><id>https://hoff2.dev/functional-fun</id><content type="html" xml:base="https://hoff2.dev/2019-10-06-functional-fun/">&lt;p&gt;The problem: You’ve got a bunch of text replacements you’d like to make in
strings. Practical application, if you need one: You’re generating messages to
be read by a speech-to-text system and there are certain words or names that
come up often that it doesn’t pronounce very well, so you’d like to replace them
with alternate “phonetic” spellings.&lt;/p&gt;

&lt;p&gt;This example is in Javascript but the concepts are broadly applicable. The list
of replacements you want to make is stored in key-value pairs, the key being
what to replace and the value being what to replace it with: we have them in a
Javascript object. Your favorite language’s equivalent might be a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Hash&lt;/code&gt;, a
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dictionary&lt;/code&gt;, a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Map&amp;lt;String, String&amp;gt;&lt;/code&gt;, etc.&lt;/p&gt;

&lt;p&gt;Here’s a totally reasonable imperative-OO solution one might come up with:&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;MessageTransformer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;constructor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;replacements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;replacements&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;replacements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;nx&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;replacements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;RegExp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`\\b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;\\b`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;gi&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;replacements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To use this you’d create a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MessageTransformer&lt;/code&gt; instance during the
initialization of your program like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;const transformer = new
MessageTransformer(replacements)&lt;/code&gt; and then use it to transform your message like
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;const fixedMessage = transformer.transform(message)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now, I have a slightly funny history with functional programming. In college I
learned some Scheme and thought FP was just about the coolest thing ever, but
almost nobody was using it in industry in those days, Java didn’t even have
lambdas yet. Then I got a job where I was writing quite a bit of Actionscript
and upon discovering that, being a ECMAscript dialect, it has closures, I went
on to write some of the worst wannabe-Lisp-in-Actionscript ever, and had great
fun doing it. More recently however, I was traumatized at a previous workplace
by “pure” FP Scala. There’s a great community to hang out if you really want to
get your impostor syndrome fired up. I now require trigger warnings for
terminology like “kleisli arrow” and “final tagless.” I’m undergoing a long slow
recovery. But I got some good things out of it, like an appreciation for
immutability. And looking at this solution made that particular spot in my brain
itch a little: we keep reassigning new values to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text&lt;/code&gt; variable (some
languages won’t even let you do this to function parameters, not that you can’t
get around it easily enough with a local variable). And then this came to me –
or rather the idea for it did; it took some work to get the actual code right:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;messageTransformer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;replacements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;replacements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;nb&quot;&gt;RegExp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`\\b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;\\b`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;ig&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;replacements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;reduce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;There’s actually two significant and completely independent refactors applied
here, relative to the first version. First is that I moved away from using a
class. The function accepts your replacements object as a parameter, analogous
to the constructor, and returns a function that does the transformations,
analogous to the method. In my head I think of this as the “objects are just a
poor-man’s closures/closures are just a poor-man’s objects” pattern, after
something I heard in that class where I learned Scheme. It could probably use a
shorter name. It changes the usage syntax a bit: to initialize it, you’d go
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;const transform = messageTransformer(replacements)&lt;/code&gt; and then use it like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;const
fixedMessage = transform(message)&lt;/code&gt;, or if you want to do both all in one go,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;const fixedMessage = messageTransformer(replacements)(message)&lt;/code&gt;. This is
potentially a pretty handy pattern you can use anytime you might create a class
with only one public method.&lt;/p&gt;

&lt;p&gt;The second and weirder refactor is that I replaced looping through the
replacements and assigning the result of performing each replacement back to the
variable with… something else. It has two parts and they are a “map” and a
“reduce”. You might have heard of MapReduce during the Big Data craze a few
years back. This is literally the same concept, but with small data, and turns
out it’s a really common FP pattern. “Map” can mean taking a collection of
something and turning it into a collection of something else by applying the
same function to each element&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;; “reduce” would then mean taking that
collection and reducing it down to one value, for example summing a list of
numbers, or even just counting how many things are in the list.&lt;/p&gt;

&lt;p&gt;In the map stage, each item in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replacements&lt;/code&gt; (or more precisely, the array if
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replacements&lt;/code&gt;’s keys) is mapped to a function that performs that replacement.
By the end of it we have an array of functions. Each function in that array is
analogous to one iteration of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;for&lt;/code&gt; loop in the first version.&lt;/p&gt;

&lt;p&gt;The reduce stage rolls all those functions into one single function by “folding”
function composition over it. This is the conceptually densest part of this
whole thing, but I’ll try my best. Imperatively speaking, it sort of loops
through the array of functions and adds them all together, so that by the end we
have a kind of chain of functions that the text gets piped through, but all in
one function. How does this work?&lt;/p&gt;

&lt;p&gt;Any time you have some function that accepts two parameters of some type and
returns something of that same type – its type signature is of the form &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(A, A)
=&amp;gt; A&lt;/code&gt; – you can use that function over a whole &lt;em&gt;list&lt;/em&gt; of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt;s by using what’s
called reducing or folding; it’s done by successively applying that function to
each item in the collection and the “so far” value. To analogize to the example
of summing a list of numbers, if you were doing it with a for-loop, each time
through the loop you add the next number in the list to the sum so far; to do
the same thing with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reduce&lt;/code&gt;, you just give it a function that does that, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(x,
y) =&amp;gt; x + y&lt;/code&gt;. Given a function that adds two numbers, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reduce&lt;/code&gt; can use it to add
a whole bunch of numbers. Give &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reduce&lt;/code&gt; a function that returns the larger of
two numbers and it can use it to find the largest of several numbers. Give
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reduce&lt;/code&gt; a function that just returns 1 and you’ll end up with a count of how
many numbers were in the list. And so on.&lt;/p&gt;

&lt;p&gt;Function composition is what it’s called when you make a new function out of two
functions – all this new function has to do is pass its argument to one of the
two functions and then pass the result of that on to the other one. This is
especially easy to do with two functions where their parameters and return
values are all the same type – that is, they both have a type signature of the
form &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B =&amp;gt; B&lt;/code&gt; (the actual letter doesn’t matter, but I don’t want to get too
confusing by re-using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt;). If you have two such functions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;g&lt;/code&gt;, the
composition of them is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x =&amp;gt; g(f(x))&lt;/code&gt;. You can write a function to do it:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;compose(f, g) = x =&amp;gt; f(g(x))&lt;/code&gt;. Anything about this sound familiar?&lt;/p&gt;

&lt;p&gt;Yes! You can “compose” the concepts of the previous two paragraphs! A function
that accepts two functions and returns the same kind of function, like our
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;compose&lt;/code&gt;, is yet another example of a function of the form &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(A, A) =&amp;gt; A&lt;/code&gt; – it
just so happens that its parameters are functions too – &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A = B =&amp;gt; B&lt;/code&gt; – making
function composition &lt;em&gt;yet another&lt;/em&gt; thing we can use in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reduce&lt;/code&gt;! And that’s
exactly what we’ve done in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reduce&lt;/code&gt; above: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(acc, f) =&amp;gt; text =&amp;gt;
f(acc(text))&lt;/code&gt;, that is, given two functions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;acc&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f&lt;/code&gt;, return a function
that takes &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text&lt;/code&gt; and returns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f(acc(text))&lt;/code&gt;. Since we’re working with a
collection of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B =&amp;gt; B&lt;/code&gt; functions (where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; means strings in our example), with
function composition we can roll them all up into one single &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B =&amp;gt; B&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;Oh, but there’s still that other weird looking parameter I’ve been glossing
over, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_ =&amp;gt; _&lt;/code&gt;. That’s just a function that takes one parameter and just returns
it. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_&lt;/code&gt; is a valid Javascript identifier, so this is just a little style choice
on my part. But why does this need to be here? Because a reduce needs a starting
value. In yet another analogy to summing a list of numbers with a loop: you need
to initialize the sum to 0 before starting the loop. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_ =&amp;gt; _&lt;/code&gt; is actually a
pretty special function to FP heads: they call it the “identity function”. It
comes in handy for just this sort of thing, because the identity function is to
function composition what 0 is to adding numbers. There’s a scary FP terminology
for this that’s hopefully about to be a bit less scary if I can explain it well
enough.&lt;/p&gt;

&lt;p&gt;It’s a concept borrowed from abstract algebra, a term for things that you can
put two of together and get the same kind of thing, and hence, things you can
reduce with: they’re called &lt;em&gt;monoids&lt;/em&gt;. For example, to speak yet again of
summing numbers, they say in algebra that “the set of real numbers under
addition forms a monoid.” A monoid is made up of a set, analogous to a type in
programming; a binary operation on that set (“binary” in the sense that it has
two operands), analogous to our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(A, A) =&amp;gt; A&lt;/code&gt;; and an &lt;em&gt;identity element&lt;/em&gt;. The
identity element is that member of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; where, when used in the binary operation,
the result is equal to the other argument – like how in real numbers, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x + 0 ==
0 + x == x&lt;/code&gt;.&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; In the same way, functions like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B =&amp;gt; B&lt;/code&gt; form a monoid under
function-composition having the identity function, often called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;, as its
identity element, because composing some &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; gets you, for all
practical purposes, the same function: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i(f(x)) == f(i(x)) == f(x)&lt;/code&gt;.&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Anyway, to get back to our little example, I thought this functional version
turned out pretty slick, it’s a neat way to conceptualize the problem, the code
is really succinct and clean, and there’s no mutability to think about. I
decided to write up a post about it for the benefit of functional programming
fans who might appreciate it the way I do, and for folks who are in the early
stages of exploring functional programming for whom all this explanation might
be educational.&lt;/p&gt;

&lt;p&gt;Now, I hear a couple of you in the back of the room there grumbling that this
implementation is probably terrible on memory usage. There’s something to that.
If your list of replacements is big enough (and that would probably have to be
pretty big), this thing could overflow the stack. It’s a common issue with
highly functional programming style, because you build just about everything out
of functions, and function calls use stack space. That said, you know what they
say about micro-optimizations. And besides, that sort of thing is quite
dependent on the language implementation. If nothing else, this was a cool
illustration of the power of functional abstractions.&lt;/p&gt;

&lt;p&gt;Implementations for pure functional languages, and others that make a priority
of enabling use of functional features, have ways of dealing with this stack
usage issue. You’ve probably heard of the optimization of tail-recursion, which
can be generalized to tail-calls. This is when a function calls another function
as the last thing it does before itself returning to its caller. If call A’s
last thing to do is to call function B (which in the case of recursion is the
same function as A), and has no further work to do afterwards, then as soon as
B’s stack frame is popped off, A’s will be too, so there wasn’t much point in
keeping the A stack frame around. Tail-call optimization basically consists of
popping off that stack frame pre-emptively. When this can be done for a
recursive function, the resulting memory usage is essentially the same as for
having used a loop. Downsides can include losing debugging information (think
stack traces). There’s also a techique called trampolining that I don’t
understand very well except that it somehow results in the memory allocation
happening on the heap instead.&lt;/p&gt;

&lt;p&gt;Anyway, hope this was interesting.&lt;/p&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;The only thing slightly esoteric here is maybe the regular expression
stuff. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\b&lt;/code&gt; is just a regex thing that matches a “boundary”, that is, a word
boundary, since we want to replace whole words; it matches the beginning or
end of the string, or of a line, or of a word. The flags &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gi&lt;/code&gt; stand for
“global” (replace all occurrences, not just the first one found) and
“insensitive” (to letter case). &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Technically the “context” in which a map occurs doesn’t have to be that
it’s a collection, there are lots of other uses; but collections are
commonly most people’s first introduction to some of these FP concepts. To
give you some idea what other things map can operate on, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;then&lt;/code&gt; method
of a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Promise&lt;/code&gt; is also basically a map; you give it a function that accepts
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; and returns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt;, and it uses it to turn a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Promise&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; in it into
a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Promise&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; in it. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;There’s a whole lot of other nuances I’m glossing over that you’re likely
to run into and understand eventually. For instance, there is such a thing
as a monoid &lt;em&gt;without&lt;/em&gt; an identity element, except it’s called a &lt;em&gt;semigroup&lt;/em&gt;
(In fact I’ve made reference to one earlier, I’ll leave it as a challenge
for the reader to spot it). And sometimes the order of arguments to the
operation matters; when it doesn’t, you have a &lt;em&gt;commutative&lt;/em&gt; monoid, like
with numbers under addition, but sometimes it does, like with strings under
concatenation, and in some of those type of cases you have elements that are
only a &lt;em&gt;left identity&lt;/em&gt; or &lt;em&gt;right identity&lt;/em&gt;… it’s a whole deep and
fascinating branch of mathematics that’s totally worth exploring further but
I’m trying to keep this article from going off the rails, and this footnote
is mostly here for the benefit of the Well-Actually Brigade. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;I’m intentionally using notation here aimed at programmers rather than
proper mathematical notation, don’t @ me. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="functional" /><category term="javascript" /><category term="monoids" /><summary type="html">The problem: You’ve got a bunch of text replacements you’d like to make in strings. Practical application, if you need one: You’re generating messages to be read by a speech-to-text system and there are certain words or names that come up often that it doesn’t pronounce very well, so you’d like to replace them with alternate “phonetic” spellings. This example is in Javascript but the concepts are broadly applicable. The list of replacements you want to make is stored in key-value pairs, the key being what to replace and the value being what to replace it with: we have them in a Javascript object. Your favorite language’s equivalent might be a Hash, a Dictionary, a Map&amp;lt;String, String&amp;gt;, etc. Here’s a totally reasonable imperative-OO solution one might come up with:1 class MessageTransformer { constructor(replacements) { this.replacements = replacements; } transform(text) { for (let str in this.replacements) { text = input.replace( RegExp(`\\b${str}\\b`, 'gi'), this.replacements[str]); } return text; } } To use this you’d create a MessageTransformer instance during the initialization of your program like const transformer = new MessageTransformer(replacements) and then use it to transform your message like const fixedMessage = transformer.transform(message). Now, I have a slightly funny history with functional programming. In college I learned some Scheme and thought FP was just about the coolest thing ever, but almost nobody was using it in industry in those days, Java didn’t even have lambdas yet. Then I got a job where I was writing quite a bit of Actionscript and upon discovering that, being a ECMAscript dialect, it has closures, I went on to write some of the worst wannabe-Lisp-in-Actionscript ever, and had great fun doing it. More recently however, I was traumatized at a previous workplace by “pure” FP Scala. There’s a great community to hang out if you really want to get your impostor syndrome fired up. I now require trigger warnings for terminology like “kleisli arrow” and “final tagless.” I’m undergoing a long slow recovery. But I got some good things out of it, like an appreciation for immutability. And looking at this solution made that particular spot in my brain itch a little: we keep reassigning new values to the text variable (some languages won’t even let you do this to function parameters, not that you can’t get around it easily enough with a local variable). And then this came to me – or rather the idea for it did; it took some work to get the actual code right: function messageTransformer(replacements) { return Object.keys(replacements).map(str =&amp;gt; text =&amp;gt; text.replace( RegExp(`\\b${str}\\b`, 'ig'), replacements[str]) ).reduce((acc, f) =&amp;gt; text =&amp;gt; f(acc(text)), _ =&amp;gt; _); } There’s actually two significant and completely independent refactors applied here, relative to the first version. First is that I moved away from using a class. The function accepts your replacements object as a parameter, analogous to the constructor, and returns a function that does the transformations, analogous to the method. In my head I think of this as the “objects are just a poor-man’s closures/closures are just a poor-man’s objects” pattern, after something I heard in that class where I learned Scheme. It could probably use a shorter name. It changes the usage syntax a bit: to initialize it, you’d go const transform = messageTransformer(replacements) and then use it like const fixedMessage = transform(message), or if you want to do both all in one go, const fixedMessage = messageTransformer(replacements)(message). This is potentially a pretty handy pattern you can use anytime you might create a class with only one public method. The second and weirder refactor is that I replaced looping through the replacements and assigning the result of performing each replacement back to the variable with… something else. It has two parts and they are a “map” and a “reduce”. You might have heard of MapReduce during the Big Data craze a few years back. This is literally the same concept, but with small data, and turns out it’s a really common FP pattern. “Map” can mean taking a collection of something and turning it into a collection of something else by applying the same function to each element2; “reduce” would then mean taking that collection and reducing it down to one value, for example summing a list of numbers, or even just counting how many things are in the list. In the map stage, each item in replacements (or more precisely, the array if replacements’s keys) is mapped to a function that performs that replacement. By the end of it we have an array of functions. Each function in that array is analogous to one iteration of the for loop in the first version. The reduce stage rolls all those functions into one single function by “folding” function composition over it. This is the conceptually densest part of this whole thing, but I’ll try my best. Imperatively speaking, it sort of loops through the array of functions and adds them all together, so that by the end we have a kind of chain of functions that the text gets piped through, but all in one function. How does this work? Any time you have some function that accepts two parameters of some type and returns something of that same type – its type signature is of the form (A, A) =&amp;gt; A – you can use that function over a whole list of As by using what’s called reducing or folding; it’s done by successively applying that function to each item in the collection and the “so far” value. To analogize to the example of summing a list of numbers, if you were doing it with a for-loop, each time through the loop you add the next number in the list to the sum so far; to do the same thing with reduce, you just give it a function that does that, (x, y) =&amp;gt; x + y. Given a function that adds two numbers, reduce can use it to add a whole bunch of numbers. Give reduce a function that returns the larger of two numbers and it can use it to find the largest of several numbers. Give reduce a function that just returns 1 and you’ll end up with a count of how many numbers were in the list. And so on. Function composition is what it’s called when you make a new function out of two functions – all this new function has to do is pass its argument to one of the two functions and then pass the result of that on to the other one. This is especially easy to do with two functions where their parameters and return values are all the same type – that is, they both have a type signature of the form B =&amp;gt; B (the actual letter doesn’t matter, but I don’t want to get too confusing by re-using A). If you have two such functions f and g, the composition of them is x =&amp;gt; g(f(x)). You can write a function to do it: compose(f, g) = x =&amp;gt; f(g(x)). Anything about this sound familiar? Yes! You can “compose” the concepts of the previous two paragraphs! A function that accepts two functions and returns the same kind of function, like our compose, is yet another example of a function of the form (A, A) =&amp;gt; A – it just so happens that its parameters are functions too – A = B =&amp;gt; B – making function composition yet another thing we can use in a reduce! And that’s exactly what we’ve done in the reduce above: (acc, f) =&amp;gt; text =&amp;gt; f(acc(text)), that is, given two functions acc and f, return a function that takes text and returns f(acc(text)). Since we’re working with a collection of B =&amp;gt; B functions (where B means strings in our example), with function composition we can roll them all up into one single B =&amp;gt; B function. Oh, but there’s still that other weird looking parameter I’ve been glossing over, _ =&amp;gt; _. That’s just a function that takes one parameter and just returns it. _ is a valid Javascript identifier, so this is just a little style choice on my part. But why does this need to be here? Because a reduce needs a starting value. In yet another analogy to summing a list of numbers with a loop: you need to initialize the sum to 0 before starting the loop. _ =&amp;gt; _ is actually a pretty special function to FP heads: they call it the “identity function”. It comes in handy for just this sort of thing, because the identity function is to function composition what 0 is to adding numbers. There’s a scary FP terminology for this that’s hopefully about to be a bit less scary if I can explain it well enough. It’s a concept borrowed from abstract algebra, a term for things that you can put two of together and get the same kind of thing, and hence, things you can reduce with: they’re called monoids. For example, to speak yet again of summing numbers, they say in algebra that “the set of real numbers under addition forms a monoid.” A monoid is made up of a set, analogous to a type in programming; a binary operation on that set (“binary” in the sense that it has two operands), analogous to our (A, A) =&amp;gt; A; and an identity element. The identity element is that member of A where, when used in the binary operation, the result is equal to the other argument – like how in real numbers, x + 0 == 0 + x == x.3 In the same way, functions like B =&amp;gt; B form a monoid under function-composition having the identity function, often called i, as its identity element, because composing some f with i gets you, for all practical purposes, the same function: i(f(x)) == f(i(x)) == f(x).4 Anyway, to get back to our little example, I thought this functional version turned out pretty slick, it’s a neat way to conceptualize the problem, the code is really succinct and clean, and there’s no mutability to think about. I decided to write up a post about it for the benefit of functional programming fans who might appreciate it the way I do, and for folks who are in the early stages of exploring functional programming for whom all this explanation might be educational. Now, I hear a couple of you in the back of the room there grumbling that this implementation is probably terrible on memory usage. There’s something to that. If your list of replacements is big enough (and that would probably have to be pretty big), this thing could overflow the stack. It’s a common issue with highly functional programming style, because you build just about everything out of functions, and function calls use stack space. That said, you know what they say about micro-optimizations. And besides, that sort of thing is quite dependent on the language implementation. If nothing else, this was a cool illustration of the power of functional abstractions. Implementations for pure functional languages, and others that make a priority of enabling use of functional features, have ways of dealing with this stack usage issue. You’ve probably heard of the optimization of tail-recursion, which can be generalized to tail-calls. This is when a function calls another function as the last thing it does before itself returning to its caller. If call A’s last thing to do is to call function B (which in the case of recursion is the same function as A), and has no further work to do afterwards, then as soon as B’s stack frame is popped off, A’s will be too, so there wasn’t much point in keeping the A stack frame around. Tail-call optimization basically consists of popping off that stack frame pre-emptively. When this can be done for a recursive function, the resulting memory usage is essentially the same as for having used a loop. Downsides can include losing debugging information (think stack traces). There’s also a techique called trampolining that I don’t understand very well except that it somehow results in the memory allocation happening on the heap instead. Anyway, hope this was interesting. The only thing slightly esoteric here is maybe the regular expression stuff. \b is just a regex thing that matches a “boundary”, that is, a word boundary, since we want to replace whole words; it matches the beginning or end of the string, or of a line, or of a word. The flags gi stand for “global” (replace all occurrences, not just the first one found) and “insensitive” (to letter case). &amp;#8617; Technically the “context” in which a map occurs doesn’t have to be that it’s a collection, there are lots of other uses; but collections are commonly most people’s first introduction to some of these FP concepts. To give you some idea what other things map can operate on, the then method of a Promise is also basically a map; you give it a function that accepts A and returns B, and it uses it to turn a Promise with A in it into a Promise with B in it. &amp;#8617; There’s a whole lot of other nuances I’m glossing over that you’re likely to run into and understand eventually. For instance, there is such a thing as a monoid without an identity element, except it’s called a semigroup (In fact I’ve made reference to one earlier, I’ll leave it as a challenge for the reader to spot it). And sometimes the order of arguments to the operation matters; when it doesn’t, you have a commutative monoid, like with numbers under addition, but sometimes it does, like with strings under concatenation, and in some of those type of cases you have elements that are only a left identity or right identity… it’s a whole deep and fascinating branch of mathematics that’s totally worth exploring further but I’m trying to keep this article from going off the rails, and this footnote is mostly here for the benefit of the Well-Actually Brigade. &amp;#8617; I’m intentionally using notation here aimed at programmers rather than proper mathematical notation, don’t @ me. &amp;#8617;</summary></entry><entry><title type="html">Ending the indentation argument</title><link href="https://hoff2.dev/2017-11-02-ending-the-indentation-argument/" rel="alternate" type="text/html" title="Ending the indentation argument" /><published>2017-11-02T02:25:02+00:00</published><updated>2017-11-02T02:25:02+00:00</updated><id>https://hoff2.dev/ending-the-indentation-argument</id><content type="html" xml:base="https://hoff2.dev/2017-11-02-ending-the-indentation-argument/">&lt;p&gt;&lt;img src=&quot;/images/line-break-after.jpg&quot; alt=&quot;original dank memeage&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I’m just going to come out and say it. I hate parameter aligning and I think it
looks like crap. Especially for functions with long names. Nothing should be
indented that far in the first place, but so much the less so when it’s just
suddenly shunted over 20+ spaces rather than the product of a series of
increasingly indented lines.&lt;/p&gt;

&lt;p&gt;This is really just an extension of my distaste for long lines. They tire my
eyes out. There is &lt;a href=&quot;http://usabilitynews.org/the-effects-of-line-length-on-reading-online-news/&quot;&gt;science&lt;/a&gt; about this. It’s why newspapers and magazines
are printed in columns. But also, when reading code, I should have to use my
horizontal scroll bar as little as possible. I used to be hardcore about an 80
column limit but with some programming languages that gets very restricting, and
then there are the matters of long names, literal strings, or long complex type
annotations, second parameter lists, implicits, and so on. There should probably
be some maximum to which only certain exceptions are allowed but I don’t have a
definite number offhand. But if I have to scroll horizontally to even &lt;em&gt;see&lt;/em&gt; the
arguments you’re passing instead of thinking I’m looking at blank lines, I’m
going to be annoyed. And if I can’t fit your code within the width of my screen,
you should really re-evaluate your life choices. Preferably I should be able to
read it fairly easily when I have two emacs buffers or Intellij editors up
side-by-side, subject to choice of a reasonable font size.&lt;/p&gt;

&lt;p&gt;This is one of those dumb holy-war issues. People are irrationally attached to
their coding styles, which themselves are a set of irrational aesthetic
preferences onto which people subconsciously hang ideas about their identity and
artistry. I think this is mostly a product of insecurity. As for
parameter-aligning, as far as I can guess, it’s an idea people get from Lisp,
and being a Lispy thing, it makes people feel smart. (Programmers do an awful
lot of terrible things for that reason, like writing needlessly complex code
where they should be abstracting something so it’s more readable, or
gratuitously using esoteric language features or idioms. I used to do a hell of
a lot of this kind of thing.) Well a lot of ideas people have gotten from Lisp
have been bad ideas, and this would be one of them.&lt;/p&gt;

&lt;p&gt;If your argument/parameter list is long enough that you don’t want to put it all
on the same line with the function name and whatever else, it’s fine to split it
over more lines. I quite like one parameter per line, especially with case
classes, but if the names are short I don’t mind grouping a few together on the
same line either – more commonly so for arguments at a function call than for
parameters at the function declaration. But you should usually start it by
line-breaking after the opening paren of the list and then just indent it a
normal indentation amount. It still reflects that you’re continuing from the
previous line, but now you won’t have to realign them all everywhere if you
change the function’s name. People seem to feel weird about line-breaking after
an opening paren even though they have no qualms about doing so after an opening
curly. Well, if this was Lisp they would &lt;em&gt;all&lt;/em&gt; be parens, so stop worrying.&lt;/p&gt;

&lt;p&gt;There’s something to be said for having consistent style in a codebase that’s
been worked on by several people, and getting it right by a standard should be
as easy to do as possible; ideally, it should be possible to
do &lt;a href=&quot;https://medium.freecodecamp.org/why-robots-should-format-our-code-159fd06d17f7&quot;&gt;automatically&lt;/a&gt; using something like &lt;a href=&quot;http://scalameta.org/scalafmt/&quot;&gt;scalafmt&lt;/a&gt; instead of leaving it
up to the capricious whims and error-proneness of humans.&lt;/p&gt;

&lt;p&gt;An indentation scheme should reflect code structure, not have to be too fiddly
to accommodate changes, and easy to enforce with a static analyzer. It should
not take up an inordinate amount of a coder’s time. Thus it is I propose a
simple scheme that I do not strictly follow myself as yet, but which I think has
quite a bit of potential. Indentation should be a number of spaces (or this
works with tabs too, but not with mixing them together, which you should never
do anyway) determined by a simple linear function &lt;em&gt;y = mx + b&lt;/em&gt;, where &lt;em&gt;b&lt;/em&gt; is
some constant indentation level started with (probably 0 in most cases); &lt;em&gt;m&lt;/em&gt;,
also a constant, is your tab width (two spaces, or three, or whatever is common
idiom of the language or decided on by team, project, or company); and &lt;em&gt;x&lt;/em&gt;, the
variable, is the number of expression delimiters (i.e. parens, brackets,
begin/end pairs) left unclosed as of the start of the line. (This doesn’t
include things that delimit literals, such as the quotes around strings.)&lt;/p&gt;

&lt;p&gt;This does have some potential to look a little odd in places where x is more
than one greater than on the preceding line, and it doesn’t account for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;case&lt;/code&gt;
or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;if&lt;/code&gt; branches that don’t have brackets around them (consider them to have
imaginary brackets maybe? Some companies’ standards just say to always use the
brackets), but generally it allows you in such cases to put the closing
delimiters on separate lines and reflect the depth of structure they are closing
without having any of them end up at the same indentation level. Closing
delimiters that are at the start of a line should end up aligned with the start
of the line they were opened on pretty easily this way.&lt;/p&gt;

&lt;p&gt;That’s all I have on that, but I’m interested in feedback. Naturally, none of
this applies to Lisp dialects which tend to have their own established
conventions and I imagine Lispers would have all sorts of reasons for hating
this idea, but I don’t much care what those grey neckbeards think. (Maybe
Clojure people would be more willing to give it a try but I don’t promise it
will look good, I haven’t tried it in any Lispy syntaxen, which as we all know
are weird anyway.) What I like about this method is its simplicity and relative
lack of special cases or aesthetic judgement calls, which make it ideal for an
automatic formatter.&lt;/p&gt;</content><author><name></name></author><category term="code" /><category term="style" /><summary type="html">I’m just going to come out and say it. I hate parameter aligning and I think it looks like crap. Especially for functions with long names. Nothing should be indented that far in the first place, but so much the less so when it’s just suddenly shunted over 20+ spaces rather than the product of a series of increasingly indented lines. This is really just an extension of my distaste for long lines. They tire my eyes out. There is science about this. It’s why newspapers and magazines are printed in columns. But also, when reading code, I should have to use my horizontal scroll bar as little as possible. I used to be hardcore about an 80 column limit but with some programming languages that gets very restricting, and then there are the matters of long names, literal strings, or long complex type annotations, second parameter lists, implicits, and so on. There should probably be some maximum to which only certain exceptions are allowed but I don’t have a definite number offhand. But if I have to scroll horizontally to even see the arguments you’re passing instead of thinking I’m looking at blank lines, I’m going to be annoyed. And if I can’t fit your code within the width of my screen, you should really re-evaluate your life choices. Preferably I should be able to read it fairly easily when I have two emacs buffers or Intellij editors up side-by-side, subject to choice of a reasonable font size. This is one of those dumb holy-war issues. People are irrationally attached to their coding styles, which themselves are a set of irrational aesthetic preferences onto which people subconsciously hang ideas about their identity and artistry. I think this is mostly a product of insecurity. As for parameter-aligning, as far as I can guess, it’s an idea people get from Lisp, and being a Lispy thing, it makes people feel smart. (Programmers do an awful lot of terrible things for that reason, like writing needlessly complex code where they should be abstracting something so it’s more readable, or gratuitously using esoteric language features or idioms. I used to do a hell of a lot of this kind of thing.) Well a lot of ideas people have gotten from Lisp have been bad ideas, and this would be one of them. If your argument/parameter list is long enough that you don’t want to put it all on the same line with the function name and whatever else, it’s fine to split it over more lines. I quite like one parameter per line, especially with case classes, but if the names are short I don’t mind grouping a few together on the same line either – more commonly so for arguments at a function call than for parameters at the function declaration. But you should usually start it by line-breaking after the opening paren of the list and then just indent it a normal indentation amount. It still reflects that you’re continuing from the previous line, but now you won’t have to realign them all everywhere if you change the function’s name. People seem to feel weird about line-breaking after an opening paren even though they have no qualms about doing so after an opening curly. Well, if this was Lisp they would all be parens, so stop worrying. There’s something to be said for having consistent style in a codebase that’s been worked on by several people, and getting it right by a standard should be as easy to do as possible; ideally, it should be possible to do automatically using something like scalafmt instead of leaving it up to the capricious whims and error-proneness of humans. An indentation scheme should reflect code structure, not have to be too fiddly to accommodate changes, and easy to enforce with a static analyzer. It should not take up an inordinate amount of a coder’s time. Thus it is I propose a simple scheme that I do not strictly follow myself as yet, but which I think has quite a bit of potential. Indentation should be a number of spaces (or this works with tabs too, but not with mixing them together, which you should never do anyway) determined by a simple linear function y = mx + b, where b is some constant indentation level started with (probably 0 in most cases); m, also a constant, is your tab width (two spaces, or three, or whatever is common idiom of the language or decided on by team, project, or company); and x, the variable, is the number of expression delimiters (i.e. parens, brackets, begin/end pairs) left unclosed as of the start of the line. (This doesn’t include things that delimit literals, such as the quotes around strings.) This does have some potential to look a little odd in places where x is more than one greater than on the preceding line, and it doesn’t account for case or if branches that don’t have brackets around them (consider them to have imaginary brackets maybe? Some companies’ standards just say to always use the brackets), but generally it allows you in such cases to put the closing delimiters on separate lines and reflect the depth of structure they are closing without having any of them end up at the same indentation level. Closing delimiters that are at the start of a line should end up aligned with the start of the line they were opened on pretty easily this way. That’s all I have on that, but I’m interested in feedback. Naturally, none of this applies to Lisp dialects which tend to have their own established conventions and I imagine Lispers would have all sorts of reasons for hating this idea, but I don’t much care what those grey neckbeards think. (Maybe Clojure people would be more willing to give it a try but I don’t promise it will look good, I haven’t tried it in any Lispy syntaxen, which as we all know are weird anyway.) What I like about this method is its simplicity and relative lack of special cases or aesthetic judgement calls, which make it ideal for an automatic formatter.</summary></entry><entry><title type="html">self =&amp;gt; abuse, or, the baclava antipattern</title><link href="https://hoff2.dev/2015-07-14-self-abuse/" rel="alternate" type="text/html" title="self =&amp;gt; abuse, or, the baclava antipattern" /><published>2015-07-14T17:00:00+00:00</published><updated>2015-07-14T17:00:00+00:00</updated><id>https://hoff2.dev/self-abuse</id><content type="html" xml:base="https://hoff2.dev/2015-07-14-self-abuse/">&lt;p&gt;Like many beginning Scala programmers, I was exposed to the
&lt;a href=&quot;http://jonasboner.com/2008/10/06/real-world-scala-dependency-injection-di/&quot;&gt;Cake&lt;/a&gt; &lt;a href=&quot;http://www.cakesolutions.net/teamblogs/2011/12/19/cake-pattern-in-depth&quot;&gt;Pattern&lt;/a&gt; early on and told
that this is how you do dependency injection in Scala. Coming from the
Ruby world I thought it looked like an awfully heavy-weight method,
but of course I didn’t know any other way yet. Right away I was placed
on a project in which the Cake pattern was apparently very much in
use, a CMS built on &lt;a href=&quot;https://www.playframework.com/&quot;&gt;Play&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I was tasked with adding a sitemap feature, such that when the path
/sitemap.xml was requested, a sitemap of the site would be rendered.
This seemed straightforward enough. I would just need to pull some
data about the site’s currently published pages from the database and
massage it into some &lt;a href=&quot;http://www.sitemaps.org/protocol.html&quot;&gt;pretty straightforward
XML&lt;/a&gt;. This being Play, I
started with a controller, and right away knew I’d need to pull in
whatever code pulls pages from the database, which was pretty easy to
find. I soon found I would also want to pull in a trait for looking at
the contents of the HTTP request. Again, no big deal.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SitemapController&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Controller&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SiteRequestExtractorComponent&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PageRepositoryComponent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sitemap&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// the magic happens...&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Ok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sitemapXML&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Simple enough, until I tried to compile:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[error] /Users/chuckhoffman/dev/cms/app/controllers/SitemapController.scala:48: illegal inheritance;
[error]  self-type controllers.SitemapController.type does not conform to models.page.CmsPageModule's selftype models.page.CmsPageModule with models.auth.UserRepositoryComponent with models.auth.GroupRepositoryComponent with models.approval.VersionApprovalComponent with models.email.EmailServiceComponent
[error]   with CmsPageModule
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Hm. Looks like somebody used that Cake pattern thingy to inject
dependencies into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CmsPageModule&lt;/code&gt; having to do with users, user
“groups,” and approval of new content. That probably has to do with
who can do what kind of updating of pages, so even though that isn’t
relevant to what I’m after since I only want to &lt;em&gt;read&lt;/em&gt; page data, not
update it, it still seems reasonable. I’ll just find the right traits
that satisfy those three things – even though I’m not really &lt;em&gt;using&lt;/em&gt;
them here – and add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;with&lt;/code&gt;s for them and all should be good.&lt;/p&gt;

&lt;p&gt;One little snag, I guess… it turns out that those traits were
“abstract”, which meant &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt;ing through the code to find the correct
“implementations,” which turned out to be
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UserRepositoryComponentPostgres&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GroupRepositoryComponentPostgres&lt;/code&gt;,
and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MongoVersionApprovalComponent&lt;/code&gt;. (This is a common sort of thing
to do, since one often wants to mock out the database for tests.) Took
a while to track them down, but eventually I did. So surely I should
be able to just add those three &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;with&lt;/code&gt;s to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SitemapController&lt;/code&gt;, add
the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;import&lt;/code&gt;s of them to the top of the file, and &lt;em&gt;now&lt;/em&gt; we’re off and
running, yeah?&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[error] /Users/chuckhoffman/dev/cms/app/controllers/SitemapController.scala:48: illegal inheritance;
[error]  self-type controllers.SitemapController.type does not conform to models.page.CmsPageModule's selftype models.page.CmsPageModule with models.auth.UserRepositoryComponent with models.auth.GroupRepositoryComponent with models.approval.VersionApprovalComponent with models.email.EmailServiceComponent
[error]   with CmsPageModule
[error]        ^
[error] /Users/chuckhoffman/dev/cms/app/controllers/SitemapController.scala:51: illegal inheritance;
[error]  self-type controllers.SitemapController.type does not conform to models.approval.MongoVersionApprovalComponent's selftype models.approval.MongoVersionApprovalComponent with models.page.PageModule with models.treasury.TreasuryModule with models.auth.UserRepositoryComponent with models.auth.GroupRepositoryComponent with models.email.EmailServiceComponent with com.banno.utils.TimeProviderComponent
[error]   with MongoVersionApprovalComponent
[error]        ^
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Oh. Looks like there’s now some kind of dependency here being enforced
between pages and something having to do with email; also, versions,
in addition to depending on pages, users, groups, and that same email
thing again, also depend on… treasuries? Huh?&lt;/p&gt;

&lt;p&gt;Plainly there’s a design problem here because I’m now being forced to
mixin traits having to do with treasuries (these are bank websites)
into a controller that makes a sitemap. At this point, however, I
don’t know Scala well enough to pull off the refactoring this needs
with all these self-types in the way. So off I go to find more traits
to mixin to satisfy those self-types. Then those traits turn out to
have self-types forcing mixin of even more traits, and so on.&lt;/p&gt;

&lt;p&gt;After a day and a half of work, I finally had a working
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SitemapController.scala&lt;/code&gt; file containing about ten lines of actual
“pulling web pages data from the database” and “building some XML,”
and a couple dozen lines of mostly irrelevant &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;with&lt;/code&gt;s and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;import&lt;/code&gt;s
just so the bastard would compile.&lt;/p&gt;

&lt;h2 id=&quot;its-time-we-had-a-talk-about-what-a-dependency-is&quot;&gt;It’s Time We Had A Talk About What A “Dependency” is&lt;/h2&gt;

&lt;p&gt;Consider this: given two modules (in the general sense of “bunch of
code that travels together”, so Scala &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;trait&lt;/code&gt;s and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;object&lt;/code&gt;s, class
instances, Ruby &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;module&lt;/code&gt;s, and so forth, all apply) A and B, having,
let’s say, a dozen functions each, if &lt;em&gt;one&lt;/em&gt; of the functions in A
calls &lt;em&gt;one&lt;/em&gt; of the functions in B, does that make B a dependency of A?&lt;/p&gt;

&lt;p&gt;I’ll save you the suspense. No, it does not. Or at least, not that
fact alone. In fact, laying aside the concern that a dozen functions
might be too many for one module anyway, it’s clear that the
dependency is between those two &lt;em&gt;functions&lt;/em&gt;, not the whole modules
they happen to be in. Which suggests that that one function in that
module is responsible for some functionality that may not be all that
relevant to what the other eleven are for. In other words, you have a
case of poor &lt;a href=&quot;http://c2.com/cgi/wiki?CouplingAndCohesion&quot;&gt;cohesion&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To the extent that we promote the Cake pattern to new Scala
programmers before they have a handle on what good design in Scala
looks like, I believe we’re putting the cart before the horse. The
cake pattern, or more generally, cake pattern-inspired self-typing,
takes your bad design and enlists the compiler to help cram it down
others’ throats. Couple this with the fact that a lot of new Scala
programmers think that: (1) because I’m writing Scala, I’m doing
functional programming; (2) functional programming is the wave of the
future and OO is on its way out, therefore (3) The past couple decades
of software design thinking, coming as it does from the old OO world,
has no relevance to me; and we get situations like my humble little
sitemap feature.&lt;/p&gt;

&lt;p&gt;Cake-patterned code, especially &lt;em&gt;badly&lt;/em&gt; cake-patterned code (which has
been the majority of cake-patterned code I’ve seen, which isn’t
surprising given the pattern’s complexity – literally nobody I’ve
talked to seems to quite completely “get” it, myself included), is
needlessly difficult to refactor, not just because of the high number
of different modules and “components” involved and/or because you have
to very carefully pick apart all the self-types (especially when those
have even more &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;with&lt;/code&gt;s in them), but also because you frequently find
yourself wanting to move some function A, but need to make sure it can
still call some function B, but B turns out to be very difficult to
&lt;em&gt;find&lt;/em&gt;, let alone move – it might be in some trait extended by the
module A is in, or it might be in some trait extended by one of those,
or some trait extended by one of &lt;em&gt;those&lt;/em&gt;, and so on, to the point
where B could literally be almost anywhere in your project or any
library it uses, and likewise anywhere in there could easily be
completely different functions with the same name. All this just so
that you can get the compiler to beat the next developer that has to
maintain this code over the head with errors if he doesn’t extend
certain traits in certain places, despite the fact that the compiler
is already perfectly good at knowing if you’re trying to call a
function that isn’t in scope.&lt;/p&gt;

&lt;p&gt;To make matters worse, most folks’ introduction to functional
programming these days still consists of pretty basic Lisp or Haskell
use throwing all your program’s functions in one global namespace with
no real modularization. It’s no surprise then if they see either the
cake pattern or trait inheritance in general as simply a way of
cramming more stuff into one namespace. Old Rails hands will hear
echoes of &lt;a href=&quot;http://blog.coreyhaines.com/2012/12/why-i-dont-use-activesupportconcern.html&quot;&gt;concerns&lt;/a&gt; or more generally, the
Ruby antipattern of “refactoring” by shoving a bunch of
seemingly-sorta-related stuff out of the way into a module (it makes
your files shorter on average, but doesn’t necessarily improve your
design any).&lt;/p&gt;

&lt;p&gt;Cohesion and coupling,
&lt;a href=&quot;https://en.wikipedia.org/wiki/Separation_of_concerns&quot;&gt;separation of concerns&lt;/a&gt;,
&lt;a href=&quot;https://en.wikipedia.org/wiki/Connascence_(computer_programming)&quot;&gt;connascence&lt;/a&gt;, even things like
&lt;a href=&quot;http://www.artima.com/articles/dci_vision.html&quot;&gt;DCI&lt;/a&gt;, these things still matter in Scala and in any of
today’s rising functional or &lt;a href=&quot;https://queue.acm.org/detail.cfm?id=2611829&quot;&gt;mostly-functional&lt;/a&gt;
programming languages – or for that matter, any programming language
that gives you the ability to stick related things together, which is
pretty much all the useful ones. (I posit that DCI may be especially
relevant to the Scala world as it seems like it would play nicely with
&lt;a href=&quot;http://debasishg.blogspot.com/2014/05/functional-patterns-in-domain-modeling.html&quot;&gt;anemic models&lt;/a&gt; based on case classes.)&lt;/p&gt;

&lt;p&gt;I hate to keep harping on my Ruby past, but I heartily recommend
&lt;a href=&quot;http://www.poodr.com/&quot;&gt;Sandi Metz’s book&lt;/a&gt; &lt;em&gt;Practical Object-Oriented Design in Ruby&lt;/em&gt;.
Scala is really just kind of like a verbose, statically-typed Ruby
plus pattern matching, when you think about it. Both combine OO and
functional concepts, both have “single-inheritance plus mixins”
multiple-inheritance; heck, even implicit conversions are just a way
better way of doing what &lt;a href=&quot;http://devblog.avdi.org/2015/05/20/so-whats-the-deal-with-ruby-refinements-anyway/&quot;&gt;refinements&lt;/a&gt; are trying
to do.&lt;/p&gt;

&lt;p&gt;Ultimately though, the cake pattern has the same problem as used to be
pointed to about &lt;a href=&quot;http://c2.com/cgi/wiki?DesignPatternsBook&quot;&gt;those other “patterns”&lt;/a&gt; when
they were all the rage: people learned the patterns early on, and
started using them everywhere because they thought that was how you’re
supposed to program now. They ended up with overly convoluted designs
because they were wedging patterns in where they weren’t necessary or
didn’t make sense, rather than first understanding the &lt;em&gt;reasons&lt;/em&gt; the
patterns existed, reaching for the patterns only when they found
themselves facing the design puzzles the patterns are intended for.&lt;/p&gt;</content><author><name></name></author><category term="scala" /><category term="cake" /><category term="OO" /><category term="design" /><category term="dependency-injection" /><summary type="html">Like many beginning Scala programmers, I was exposed to the Cake Pattern early on and told that this is how you do dependency injection in Scala. Coming from the Ruby world I thought it looked like an awfully heavy-weight method, but of course I didn’t know any other way yet. Right away I was placed on a project in which the Cake pattern was apparently very much in use, a CMS built on Play. I was tasked with adding a sitemap feature, such that when the path /sitemap.xml was requested, a sitemap of the site would be rendered. This seemed straightforward enough. I would just need to pull some data about the site’s currently published pages from the database and massage it into some pretty straightforward XML. This being Play, I started with a controller, and right away knew I’d need to pull in whatever code pulls pages from the database, which was pretty easy to find. I soon found I would also want to pull in a trait for looking at the contents of the HTTP request. Again, no big deal. trait SitemapController extends Controller with SiteRequestExtractorComponent with PageRepositoryComponent { def sitemap = { // the magic happens... Ok(sitemapXML) } } Simple enough, until I tried to compile: [error] /Users/chuckhoffman/dev/cms/app/controllers/SitemapController.scala:48: illegal inheritance; [error] self-type controllers.SitemapController.type does not conform to models.page.CmsPageModule's selftype models.page.CmsPageModule with models.auth.UserRepositoryComponent with models.auth.GroupRepositoryComponent with models.approval.VersionApprovalComponent with models.email.EmailServiceComponent [error] with CmsPageModule Hm. Looks like somebody used that Cake pattern thingy to inject dependencies into CmsPageModule having to do with users, user “groups,” and approval of new content. That probably has to do with who can do what kind of updating of pages, so even though that isn’t relevant to what I’m after since I only want to read page data, not update it, it still seems reasonable. I’ll just find the right traits that satisfy those three things – even though I’m not really using them here – and add withs for them and all should be good. One little snag, I guess… it turns out that those traits were “abstract”, which meant greping through the code to find the correct “implementations,” which turned out to be UserRepositoryComponentPostgres, GroupRepositoryComponentPostgres, and MongoVersionApprovalComponent. (This is a common sort of thing to do, since one often wants to mock out the database for tests.) Took a while to track them down, but eventually I did. So surely I should be able to just add those three withs to the SitemapController, add the imports of them to the top of the file, and now we’re off and running, yeah? [error] /Users/chuckhoffman/dev/cms/app/controllers/SitemapController.scala:48: illegal inheritance; [error] self-type controllers.SitemapController.type does not conform to models.page.CmsPageModule's selftype models.page.CmsPageModule with models.auth.UserRepositoryComponent with models.auth.GroupRepositoryComponent with models.approval.VersionApprovalComponent with models.email.EmailServiceComponent [error] with CmsPageModule [error] ^ [error] /Users/chuckhoffman/dev/cms/app/controllers/SitemapController.scala:51: illegal inheritance; [error] self-type controllers.SitemapController.type does not conform to models.approval.MongoVersionApprovalComponent's selftype models.approval.MongoVersionApprovalComponent with models.page.PageModule with models.treasury.TreasuryModule with models.auth.UserRepositoryComponent with models.auth.GroupRepositoryComponent with models.email.EmailServiceComponent with com.banno.utils.TimeProviderComponent [error] with MongoVersionApprovalComponent [error] ^ Oh. Looks like there’s now some kind of dependency here being enforced between pages and something having to do with email; also, versions, in addition to depending on pages, users, groups, and that same email thing again, also depend on… treasuries? Huh? Plainly there’s a design problem here because I’m now being forced to mixin traits having to do with treasuries (these are bank websites) into a controller that makes a sitemap. At this point, however, I don’t know Scala well enough to pull off the refactoring this needs with all these self-types in the way. So off I go to find more traits to mixin to satisfy those self-types. Then those traits turn out to have self-types forcing mixin of even more traits, and so on. After a day and a half of work, I finally had a working SitemapController.scala file containing about ten lines of actual “pulling web pages data from the database” and “building some XML,” and a couple dozen lines of mostly irrelevant withs and imports just so the bastard would compile. It’s Time We Had A Talk About What A “Dependency” is Consider this: given two modules (in the general sense of “bunch of code that travels together”, so Scala traits and objects, class instances, Ruby modules, and so forth, all apply) A and B, having, let’s say, a dozen functions each, if one of the functions in A calls one of the functions in B, does that make B a dependency of A? I’ll save you the suspense. No, it does not. Or at least, not that fact alone. In fact, laying aside the concern that a dozen functions might be too many for one module anyway, it’s clear that the dependency is between those two functions, not the whole modules they happen to be in. Which suggests that that one function in that module is responsible for some functionality that may not be all that relevant to what the other eleven are for. In other words, you have a case of poor cohesion. To the extent that we promote the Cake pattern to new Scala programmers before they have a handle on what good design in Scala looks like, I believe we’re putting the cart before the horse. The cake pattern, or more generally, cake pattern-inspired self-typing, takes your bad design and enlists the compiler to help cram it down others’ throats. Couple this with the fact that a lot of new Scala programmers think that: (1) because I’m writing Scala, I’m doing functional programming; (2) functional programming is the wave of the future and OO is on its way out, therefore (3) The past couple decades of software design thinking, coming as it does from the old OO world, has no relevance to me; and we get situations like my humble little sitemap feature. Cake-patterned code, especially badly cake-patterned code (which has been the majority of cake-patterned code I’ve seen, which isn’t surprising given the pattern’s complexity – literally nobody I’ve talked to seems to quite completely “get” it, myself included), is needlessly difficult to refactor, not just because of the high number of different modules and “components” involved and/or because you have to very carefully pick apart all the self-types (especially when those have even more withs in them), but also because you frequently find yourself wanting to move some function A, but need to make sure it can still call some function B, but B turns out to be very difficult to find, let alone move – it might be in some trait extended by the module A is in, or it might be in some trait extended by one of those, or some trait extended by one of those, and so on, to the point where B could literally be almost anywhere in your project or any library it uses, and likewise anywhere in there could easily be completely different functions with the same name. All this just so that you can get the compiler to beat the next developer that has to maintain this code over the head with errors if he doesn’t extend certain traits in certain places, despite the fact that the compiler is already perfectly good at knowing if you’re trying to call a function that isn’t in scope. To make matters worse, most folks’ introduction to functional programming these days still consists of pretty basic Lisp or Haskell use throwing all your program’s functions in one global namespace with no real modularization. It’s no surprise then if they see either the cake pattern or trait inheritance in general as simply a way of cramming more stuff into one namespace. Old Rails hands will hear echoes of concerns or more generally, the Ruby antipattern of “refactoring” by shoving a bunch of seemingly-sorta-related stuff out of the way into a module (it makes your files shorter on average, but doesn’t necessarily improve your design any). Cohesion and coupling, separation of concerns, connascence, even things like DCI, these things still matter in Scala and in any of today’s rising functional or mostly-functional programming languages – or for that matter, any programming language that gives you the ability to stick related things together, which is pretty much all the useful ones. (I posit that DCI may be especially relevant to the Scala world as it seems like it would play nicely with anemic models based on case classes.) I hate to keep harping on my Ruby past, but I heartily recommend Sandi Metz’s book Practical Object-Oriented Design in Ruby. Scala is really just kind of like a verbose, statically-typed Ruby plus pattern matching, when you think about it. Both combine OO and functional concepts, both have “single-inheritance plus mixins” multiple-inheritance; heck, even implicit conversions are just a way better way of doing what refinements are trying to do. Ultimately though, the cake pattern has the same problem as used to be pointed to about those other “patterns” when they were all the rage: people learned the patterns early on, and started using them everywhere because they thought that was how you’re supposed to program now. They ended up with overly convoluted designs because they were wedging patterns in where they weren’t necessary or didn’t make sense, rather than first understanding the reasons the patterns existed, reaching for the patterns only when they found themselves facing the design puzzles the patterns are intended for.</summary></entry><entry><title type="html">The TDD That Can be Spoken Is Not the Eternal TDD</title><link href="https://hoff2.dev/2014-01-24-tdd_is_a_path/" rel="alternate" type="text/html" title="The TDD That Can be Spoken Is Not the Eternal TDD" /><published>2014-01-24T12:00:00+00:00</published><updated>2014-01-24T12:00:00+00:00</updated><id>https://hoff2.dev/tdd_is_a_path</id><content type="html" xml:base="https://hoff2.dev/2014-01-24-tdd_is_a_path/">&lt;p&gt;For all the talk on the interbutts about TDD and related topics, it
sure seems like as a working programmer I run into a startling amount
of projects – a great majority, really – that either have no tests,
or have old useless tests that were abandoned long ago; and a
startling number of developers who still don’t write any tests at all,
let alone practice a TDD style of work. It’s as if as an industry
we’re all putting up a big front about how important testing and TDD
is to us but then when the fingers hit the keyboard, it’s all lies.
That’s probably not really the case, but rather that test-infected
developers are a small but vocal minority – that developers that test
tend to also be the kinds of developers that blog, make podcasts,
present at conferences, write books, and so on, but these happen to
only be a sadly small percentage of all the developers out there
cranking out code. But this minority has been talking about testing
for what, a decade now at least? So why hasn’t the portion of
developers seriously testing grown faster?&lt;/p&gt;

&lt;p&gt;Once you’ve got going with TDD or even just a little automated
testing, and have come to rely on it, one of the most frustrating
things is to find yourself having to collaborate with others who have
not, and have no interest in it. You really don’t want to leave an
only partly-tested system, meanwhile these other developers on your
project will make changes that break your tests with impunity. The
path of least resistance is to fall back in line with the rest of your
team and go back to what one of my professors back at UNI referred to
as the “compile-crap” cycle – a loop of add or change some code, try
to compile it, say “crap” when fails, repeat – except for interpreted
languages, substitute in place of the compile step, running the
application and trying to “use” it, so maybe call it the “run-crap”
cycle. This friction may well be one of the biggest factors slowing
the adoption of TDD; but the less developers are testing, the more it
will happen, so it’s also an effect. It’s a vicious feedback loop.&lt;/p&gt;

&lt;p&gt;Then there’s maintenance, and/or working with “legacy” code, without
tests, or with bad tests. Many a project is written with no tests ever
– just banging out code in a run-crap loop.&lt;/p&gt;

&lt;p&gt;Others start out with tests, but somewhere during the development
process something changes and the team reverts back to run-crap. Why
do they do this? It may be that members of the development team have
been swapped out for some, shall we say, ahem, “cheaper” ones; this
might happen when the product is launched and comes to be seen as in
“maintenance” phase, but it also happens earlier on. Or it may be that
the developers reverted to comfortable old habits in the face of
schedule pressure from management – after all TDD can be slower in
the short-term, especially when you’re new at it, and it’s easy to
lose focus on careful discipline in favor of short-term speed (or at
least the &lt;em&gt;appearance&lt;/em&gt; thereof) when the management is breathing down
your neck or freaking out at you.&lt;/p&gt;

&lt;p&gt;In any case, the eventual result is either no tests, or tests that are
no help because most of them are failing because they express
requirements that have since changed – which might be even worse than
no tests at all; it can look like the best way to deal with it is to
just nuke the whole suite.&lt;/p&gt;

&lt;p&gt;But then what? Touching on how TDD informs design, it’s well
established that code written without TDD is likely to contain design
that is much harder to write tests for, with lots more coupling and
dependency snarls. As requests for bug fixes and new features come in
for such a system, how do you work on it in a test-driven manner?
Stopping the world long enough to retrofit a complete suite of
difficult-to-write tests isn’t feasible and chances are there’s no
documentation you can consult when you hit all those ambiguities in
what some code &lt;em&gt;should&lt;/em&gt; be doing, so you’re likely not to even know
what exactly to test for – the definition of “legacy code” as being
that for which requirements have been lost. Practicing TDD on
greenfield projects is relatively obvious; but the vast majority of
development time is spent in maintenance, and legacy/maintenance is
“advanced” TDD. I’m probably not telling you anything you don’t
already know. Michael Feathers’ book &lt;em&gt;Working Effectively With Legacy
Code&lt;/em&gt; is the authoritative source on the subject, but if it’s not
feasible to halt work long enough to Test All The Things, then is it
feasible to halt work long enough to read a book, especially if you’re
a painfully slow ADHD-stricken reader like myself? Yet again, it’s
much easier to go back to the good old irritating-but-familiar
run-crap loop.&lt;/p&gt;

&lt;p&gt;It’s clear that as an industry we only stand to benefit by spreading
the good word of TDD far and wide. The more it’s being done, the
better. But the factors I’ve just outlined present very real obstacles
to its adoption. It’s a long-term project of raising awareness and
educating the developer public. Meanwhile, what can you as an
individual developer do? For starters, if you really want to do TDD
but are stuck in a job where everyone’s oblivious to the concept, it’s
probably not worth your time trying to force that kind of sea change
on your own. You’re swimming against a torrent. My advice? Find a
company that’s as serious about it as you are, and go work there
instead.&lt;/p&gt;

&lt;p&gt;I myself don’t even consider my work to be test-driven. I’m a
&lt;em&gt;believer&lt;/em&gt; in TDD, and I make the best, sincerest attempts at it I can
relative to the time and energy constraints within which I am working.
I certainly don’t consider myself an enlightened TDD guru. I even come
out and say just that right in the introduction to my résumé. What’s
that, you’re supposed to talk yourself up in a résumé and make
yourself sound like the answer to all a company’s prayers so that you
get the job? I don’t believe in that. I’m hoping to score a gig
working with test-driven developers but I don’t want to be expected to
be perfect at it from day one if such a company hires me; I want such
a job because I know I have a lot to learn and am looking for
advantageous situations in which to learn. It pains me that such
honesty should seem radical, but in my experience, the pains that come
from getting oneself into the wrong situations are worse.&lt;/p&gt;

&lt;p&gt;Developers can also tend to be a prickly lot with a healthy distrust
of dogma. And sometimes the practices of what I might call “strong” or
“pure” TDD can feel like a dogma, especially when delivered in a kind
of hellfire-and-brimstone way a la your average Bob Martin conference
talk. I don’t care for the idea that you cannot be considered a
professional developer if you don’t practice TDD (and by whose
standard/definition of TDD anyway?).&lt;/p&gt;

&lt;p&gt;As I have begin to view it, TDD isn’t something you just start doing
and are able to do all of it flawlessly from the get-go. Among the
many concepts and tools you’ll need in order to be able to completely
test-drive all parts of a system, there’s things like the delicate art
of mocking, how to fake a logged-in user, how to make a unit test
truly isolated, how to mock a collaborator without making the test
useless, what different kinds of tests there are, and a lot of
subjective experience-based intuition about what tools and techniques
are best suited for what kinds of tests and situations. It can all
feel really daunting.&lt;/p&gt;

&lt;p&gt;Especially in the context of a web applications, and then especially
when you’re working with a framework such as Rails, there’s a big
learning curve, one that I think would be better viewed as a long
process of continual improvement. There will be difficulties along the
way, but in the meantime you still have to get work done and people
are still paying you. To say you can’t call yourself a professional
until you’ve already mastered every aspect of TDD feels, frankly,
insultingly elitist. You have to crawl before you can walk before you
can run before you can fly. Doing some testing still beats the pants
off not doing any. I don’t think agile development processes was ever
meant to be dogmatic. The processes should be flexible, adaptable,
pragmatic – just like the code you hope to write when you use TDD to
guide the design.&lt;/p&gt;

&lt;p&gt;The problem so far is that too seldom is TDD presented in this way.
Instead it’s usually framed as, you’re either TDD or you’re not. (And
by the way what constitutes TDD is a constantly moving target.) That
way of looking at TDD isn’t going to help you or anybody else adopt
it. All it does is feed into your impostor syndrome.&lt;/p&gt;

&lt;p&gt;I think it’s worth reminding oneself that guys like &lt;a href=&quot;http://cleancoders.com/codecast/bawch-episode-1/show&quot;&gt;Corey
Haines&lt;/a&gt; took years to get that good at a totally test-driven
style. I mean just watch that video. He’s test-driving every little
piece of a Rails application totally outside-in, that is, starting
with the “outermost” layers, what the user sees, the GUI, the views,
and working inward towards the hard candy database center. There are
so many points where he shows techniques for isolating the piece he’s
working on, hacks to circumvent the coupling inherent in Rails’s
architecture in order to get Rails to let him keep working at an upper
level of the application instead of bombing out with an error about
some lower-level piece not existing yet. Techniques that I just don’t
think I would be able to absorb by rote, that he seems to have arrived
at on his own through leaps of intuition and experience that I don’t
see myself being able to duplicate. It’s quite beautiful but even
though I know he wants to sell these videos, I concluded that this
wasn’t going to work for me. We all gotta find our own way, I guess.&lt;/p&gt;

&lt;p&gt;That kind of outside-in TDD approach is very much in-vogue right now,
though. And another thing that’s very in-vogue at the moment, and a
very useful guiding concept, is the &lt;a href=&quot;http://blog.codeclimate.com/blog/2013/10/09/rails-testing-pyramid/&quot;&gt;Rails Testing Pyramid&lt;/a&gt;.
The tl;dr of it is that your unit tests are the most important, and
should be the type of test you have the most of; and as you look up
the Rails stack each kind of test is slower and more integrated and
rests on the foundation of those below it.&lt;/p&gt;

&lt;p&gt;The mosaic of types of tests you might use in a Rails application is
larger than they present in that article, and I think several of them
can be grouped together in the “service tests” category, but you can
see approximately where they would live in the pyramid relative to
each other – in order starting from the bottom: unit tests, model
tests, controller tests, request tests, helper tests, view tests,
client-side/javascript tests (which might be a whole other pyramid
actually), and finally acceptance tests/features. As you go up the
pyramid in this way too, you find that the tools and techniques become
more advanced in skill, or at least are usually assumed to be and
presented as such: testing literature usually begins with unit tests,
and Rails-oriented testing literature usually begins with what the
Rails community have traditionally &lt;em&gt;called&lt;/em&gt; “unit tests,” which are
tests at the model layer, which might be integrated with related
models and might be tied to the database, or might be totally isolated
from both, depending on how well you’ve gotten the hang of the
higher-level skills of mocking and isolating from the database.&lt;/p&gt;

&lt;p&gt;But here’s what I realized a while ago: when you put the outside-in
approach together with the Rails Testing Pyramid, the implication is
that you are building a pyramid top-first.&lt;/p&gt;

&lt;p&gt;Does that even make sense? I mean, I realize we’re talking about
software here, not big blocks of stone. It’s a metaphor, but I think
there’s useful insight to be gotten from metaphors. The Agile and XP
literature &lt;a href=&quot;http://reports-archive.adm.cs.cmu.edu/anon/isri/CMU-ISRI-03-100.pdf&quot;&gt;says so too&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You’ve got a pyramid of your &lt;em&gt;own&lt;/em&gt; to build: your repertoire of
testing skills. And if building a pyramid it top-first seems
counterintuitive, building all of it at once certainly should.&lt;/p&gt;

&lt;p&gt;All your favorite TDD gurus had to have started somewhere – probably
with a few simple unit or model tests just like most of us probably
did. If you get too attached to an ideal of TDD enlightenment, it can
be discouraging. Better to keep TDD in mind as a guiding principle, an
ideal, then just &lt;em&gt;start testing&lt;/em&gt;. As you progress, keep a sharp eye on
ways to get &lt;em&gt;more&lt;/em&gt; test-driven – places where more testing, new kinds
of tests, new techniques and tools, can help you be more confident in
your code with more ease. Tackle learning those as you feel yourself
become ready for them.&lt;/p&gt;

&lt;p&gt;I recently had this idea for a presentation that would bring
together concepts from &lt;a href=&quot;http://www.artima.com/weblogs/viewpost.jsp?thread=194506&quot;&gt;Testivus&lt;/a&gt; with a sprinkling of
Buddhist philosophy. The saying “&lt;a href=&quot;http://www.thebigdrumintheskyreligion.com/1/post/2013/10/cloud-hammer.html&quot;&gt;if you meet the Buddha on the road,
kill him&lt;/a&gt;” seemed prescient, but I wouldn’t want to be
misinterpreted as advocating anyone’s murder.&lt;/p&gt;

&lt;p&gt;I think it can be pretty easy to sell developers on &lt;em&gt;some&lt;/em&gt; kind of
automated testing. There’s a big win right away in that you can spend
more time writing useful code versus less time filling out the same
web form over and over like a trained monkey. That’s already going to
make you more productive and your day more enjoyable. Traditionally
the introduction to testing has been at the unit test level, but I
almost wonder whether it would be better, now that there are good
tools for it, to start from full-stack acceptance tests right away and
go as far with that as you can. You may end up with slow, very
coarse-grained tests this way (and it’s for this reason that so many
testing advocates will tell you it’s wrong), but at least they will
exercise most of the system and you will catch defects and regressions
you were likely to miss otherwise. Of course any developer/team
working in this way will end up experiencing some pain when the test
uncovers a bug but can’t pinpoint where in the system it is
originating; but that’s a good pain point to have if it can be turned
into a motivation to dig into those deeper levels of testing.&lt;/p&gt;

&lt;p&gt;Convincing developers to test shouldn’t be as hard as it looks like
it’s been made. It’s time to simplify the pitch: Testing is a path to
reduce suffering. You will be learning it forever.&lt;/p&gt;</content><author><name></name></author><category term="rails" /><category term="tdd" /><summary type="html">For all the talk on the interbutts about TDD and related topics, it sure seems like as a working programmer I run into a startling amount of projects – a great majority, really – that either have no tests, or have old useless tests that were abandoned long ago; and a startling number of developers who still don’t write any tests at all, let alone practice a TDD style of work. It’s as if as an industry we’re all putting up a big front about how important testing and TDD is to us but then when the fingers hit the keyboard, it’s all lies. That’s probably not really the case, but rather that test-infected developers are a small but vocal minority – that developers that test tend to also be the kinds of developers that blog, make podcasts, present at conferences, write books, and so on, but these happen to only be a sadly small percentage of all the developers out there cranking out code. But this minority has been talking about testing for what, a decade now at least? So why hasn’t the portion of developers seriously testing grown faster? Once you’ve got going with TDD or even just a little automated testing, and have come to rely on it, one of the most frustrating things is to find yourself having to collaborate with others who have not, and have no interest in it. You really don’t want to leave an only partly-tested system, meanwhile these other developers on your project will make changes that break your tests with impunity. The path of least resistance is to fall back in line with the rest of your team and go back to what one of my professors back at UNI referred to as the “compile-crap” cycle – a loop of add or change some code, try to compile it, say “crap” when fails, repeat – except for interpreted languages, substitute in place of the compile step, running the application and trying to “use” it, so maybe call it the “run-crap” cycle. This friction may well be one of the biggest factors slowing the adoption of TDD; but the less developers are testing, the more it will happen, so it’s also an effect. It’s a vicious feedback loop. Then there’s maintenance, and/or working with “legacy” code, without tests, or with bad tests. Many a project is written with no tests ever – just banging out code in a run-crap loop. Others start out with tests, but somewhere during the development process something changes and the team reverts back to run-crap. Why do they do this? It may be that members of the development team have been swapped out for some, shall we say, ahem, “cheaper” ones; this might happen when the product is launched and comes to be seen as in “maintenance” phase, but it also happens earlier on. Or it may be that the developers reverted to comfortable old habits in the face of schedule pressure from management – after all TDD can be slower in the short-term, especially when you’re new at it, and it’s easy to lose focus on careful discipline in favor of short-term speed (or at least the appearance thereof) when the management is breathing down your neck or freaking out at you. In any case, the eventual result is either no tests, or tests that are no help because most of them are failing because they express requirements that have since changed – which might be even worse than no tests at all; it can look like the best way to deal with it is to just nuke the whole suite. But then what? Touching on how TDD informs design, it’s well established that code written without TDD is likely to contain design that is much harder to write tests for, with lots more coupling and dependency snarls. As requests for bug fixes and new features come in for such a system, how do you work on it in a test-driven manner? Stopping the world long enough to retrofit a complete suite of difficult-to-write tests isn’t feasible and chances are there’s no documentation you can consult when you hit all those ambiguities in what some code should be doing, so you’re likely not to even know what exactly to test for – the definition of “legacy code” as being that for which requirements have been lost. Practicing TDD on greenfield projects is relatively obvious; but the vast majority of development time is spent in maintenance, and legacy/maintenance is “advanced” TDD. I’m probably not telling you anything you don’t already know. Michael Feathers’ book Working Effectively With Legacy Code is the authoritative source on the subject, but if it’s not feasible to halt work long enough to Test All The Things, then is it feasible to halt work long enough to read a book, especially if you’re a painfully slow ADHD-stricken reader like myself? Yet again, it’s much easier to go back to the good old irritating-but-familiar run-crap loop. It’s clear that as an industry we only stand to benefit by spreading the good word of TDD far and wide. The more it’s being done, the better. But the factors I’ve just outlined present very real obstacles to its adoption. It’s a long-term project of raising awareness and educating the developer public. Meanwhile, what can you as an individual developer do? For starters, if you really want to do TDD but are stuck in a job where everyone’s oblivious to the concept, it’s probably not worth your time trying to force that kind of sea change on your own. You’re swimming against a torrent. My advice? Find a company that’s as serious about it as you are, and go work there instead. I myself don’t even consider my work to be test-driven. I’m a believer in TDD, and I make the best, sincerest attempts at it I can relative to the time and energy constraints within which I am working. I certainly don’t consider myself an enlightened TDD guru. I even come out and say just that right in the introduction to my résumé. What’s that, you’re supposed to talk yourself up in a résumé and make yourself sound like the answer to all a company’s prayers so that you get the job? I don’t believe in that. I’m hoping to score a gig working with test-driven developers but I don’t want to be expected to be perfect at it from day one if such a company hires me; I want such a job because I know I have a lot to learn and am looking for advantageous situations in which to learn. It pains me that such honesty should seem radical, but in my experience, the pains that come from getting oneself into the wrong situations are worse. Developers can also tend to be a prickly lot with a healthy distrust of dogma. And sometimes the practices of what I might call “strong” or “pure” TDD can feel like a dogma, especially when delivered in a kind of hellfire-and-brimstone way a la your average Bob Martin conference talk. I don’t care for the idea that you cannot be considered a professional developer if you don’t practice TDD (and by whose standard/definition of TDD anyway?). As I have begin to view it, TDD isn’t something you just start doing and are able to do all of it flawlessly from the get-go. Among the many concepts and tools you’ll need in order to be able to completely test-drive all parts of a system, there’s things like the delicate art of mocking, how to fake a logged-in user, how to make a unit test truly isolated, how to mock a collaborator without making the test useless, what different kinds of tests there are, and a lot of subjective experience-based intuition about what tools and techniques are best suited for what kinds of tests and situations. It can all feel really daunting. Especially in the context of a web applications, and then especially when you’re working with a framework such as Rails, there’s a big learning curve, one that I think would be better viewed as a long process of continual improvement. There will be difficulties along the way, but in the meantime you still have to get work done and people are still paying you. To say you can’t call yourself a professional until you’ve already mastered every aspect of TDD feels, frankly, insultingly elitist. You have to crawl before you can walk before you can run before you can fly. Doing some testing still beats the pants off not doing any. I don’t think agile development processes was ever meant to be dogmatic. The processes should be flexible, adaptable, pragmatic – just like the code you hope to write when you use TDD to guide the design. The problem so far is that too seldom is TDD presented in this way. Instead it’s usually framed as, you’re either TDD or you’re not. (And by the way what constitutes TDD is a constantly moving target.) That way of looking at TDD isn’t going to help you or anybody else adopt it. All it does is feed into your impostor syndrome. I think it’s worth reminding oneself that guys like Corey Haines took years to get that good at a totally test-driven style. I mean just watch that video. He’s test-driving every little piece of a Rails application totally outside-in, that is, starting with the “outermost” layers, what the user sees, the GUI, the views, and working inward towards the hard candy database center. There are so many points where he shows techniques for isolating the piece he’s working on, hacks to circumvent the coupling inherent in Rails’s architecture in order to get Rails to let him keep working at an upper level of the application instead of bombing out with an error about some lower-level piece not existing yet. Techniques that I just don’t think I would be able to absorb by rote, that he seems to have arrived at on his own through leaps of intuition and experience that I don’t see myself being able to duplicate. It’s quite beautiful but even though I know he wants to sell these videos, I concluded that this wasn’t going to work for me. We all gotta find our own way, I guess. That kind of outside-in TDD approach is very much in-vogue right now, though. And another thing that’s very in-vogue at the moment, and a very useful guiding concept, is the Rails Testing Pyramid. The tl;dr of it is that your unit tests are the most important, and should be the type of test you have the most of; and as you look up the Rails stack each kind of test is slower and more integrated and rests on the foundation of those below it. The mosaic of types of tests you might use in a Rails application is larger than they present in that article, and I think several of them can be grouped together in the “service tests” category, but you can see approximately where they would live in the pyramid relative to each other – in order starting from the bottom: unit tests, model tests, controller tests, request tests, helper tests, view tests, client-side/javascript tests (which might be a whole other pyramid actually), and finally acceptance tests/features. As you go up the pyramid in this way too, you find that the tools and techniques become more advanced in skill, or at least are usually assumed to be and presented as such: testing literature usually begins with unit tests, and Rails-oriented testing literature usually begins with what the Rails community have traditionally called “unit tests,” which are tests at the model layer, which might be integrated with related models and might be tied to the database, or might be totally isolated from both, depending on how well you’ve gotten the hang of the higher-level skills of mocking and isolating from the database. But here’s what I realized a while ago: when you put the outside-in approach together with the Rails Testing Pyramid, the implication is that you are building a pyramid top-first. Does that even make sense? I mean, I realize we’re talking about software here, not big blocks of stone. It’s a metaphor, but I think there’s useful insight to be gotten from metaphors. The Agile and XP literature says so too. You’ve got a pyramid of your own to build: your repertoire of testing skills. And if building a pyramid it top-first seems counterintuitive, building all of it at once certainly should. All your favorite TDD gurus had to have started somewhere – probably with a few simple unit or model tests just like most of us probably did. If you get too attached to an ideal of TDD enlightenment, it can be discouraging. Better to keep TDD in mind as a guiding principle, an ideal, then just start testing. As you progress, keep a sharp eye on ways to get more test-driven – places where more testing, new kinds of tests, new techniques and tools, can help you be more confident in your code with more ease. Tackle learning those as you feel yourself become ready for them. I recently had this idea for a presentation that would bring together concepts from Testivus with a sprinkling of Buddhist philosophy. The saying “if you meet the Buddha on the road, kill him” seemed prescient, but I wouldn’t want to be misinterpreted as advocating anyone’s murder. I think it can be pretty easy to sell developers on some kind of automated testing. There’s a big win right away in that you can spend more time writing useful code versus less time filling out the same web form over and over like a trained monkey. That’s already going to make you more productive and your day more enjoyable. Traditionally the introduction to testing has been at the unit test level, but I almost wonder whether it would be better, now that there are good tools for it, to start from full-stack acceptance tests right away and go as far with that as you can. You may end up with slow, very coarse-grained tests this way (and it’s for this reason that so many testing advocates will tell you it’s wrong), but at least they will exercise most of the system and you will catch defects and regressions you were likely to miss otherwise. Of course any developer/team working in this way will end up experiencing some pain when the test uncovers a bug but can’t pinpoint where in the system it is originating; but that’s a good pain point to have if it can be turned into a motivation to dig into those deeper levels of testing. Convincing developers to test shouldn’t be as hard as it looks like it’s been made. It’s time to simplify the pitch: Testing is a path to reduce suffering. You will be learning it forever.</summary></entry><entry><title type="html">Counting shared tags (or other commonalities) with a SQL view</title><link href="https://hoff2.dev/2013-12-04-counting-shared-tags-with-a-sql-view/" rel="alternate" type="text/html" title="Counting shared tags (or other commonalities) with a SQL view" /><published>2013-12-04T12:00:00+00:00</published><updated>2013-12-04T12:00:00+00:00</updated><id>https://hoff2.dev/counting-shared-tags-with-a-sql-view</id><content type="html" xml:base="https://hoff2.dev/2013-12-04-counting-shared-tags-with-a-sql-view/">&lt;p&gt;Occasionally I surprise myself and end up feeling a desire to write
about it and toot my own horn a little bit. What better place to do
that than on a professional blog at least part of the purpose of which
is to show prospective employers or clients that I’m good at stuff?&lt;/p&gt;

&lt;h2 id=&quot;im-pretty-good-i-guess&quot;&gt;I’m pretty good, I guess&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;note: personal background jabber, skip this section at will&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I’m largely self-taught in the area of databases and SQL. The only
course I ever took on the subject was a quarter-length database class,
circa 1999, at Hamilton College (since bought up by Kaplan, I think)
as part of their two-year IT degree program. It used Microsoft Access
and was very beginner-level and I think I might have been out sick on
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;join&lt;/code&gt;s day. Later when pursuing my Computer Science degree I avoided
the databases course out of dislike for the professor who taught it;
the alternative course to meet the same requirement had more to do
with text indexing, information theory – search-engine kind of stuff
– and oddly enough, the course taught and used an open-source
multi-dimensional hierarchical database and MUMPS compiler developed
by the course’s professor (multi-dimensional databases are quite good
at storing and comparing things like, vectors of the occurrences of
hundreds of different words in a bunch of textual articles). So, yes,
I learned MUMPS in college instead of SQL. Actually, you can
&lt;a href=&quot;http://www.cs.uni.edu/~okane/&quot;&gt;download&lt;/a&gt; and make-install the C++
code for the MUMPS compiler we used yourself, which compiles MUMPS
into C++, if you ever get a wild urge to do such a thing. In fact, I’d
recommend it to my fellow programming language nerds, especially those
interested in old, obscure, or just plain weird languages. At the very
least you’ll have a little fun with it; and I believe MUMPS is even
still in use in some corners of the health care industry, so you’d be
picking up a skill that’s in some demand yet increasingly difficult to
hire for. (While you’re at it, check out Dr. O’Kane’s &lt;a href=&quot;http://amzn.com/1438243383&quot;&gt;MUMPS
book&lt;/a&gt; and his rollicking, action-packed
&lt;a href=&quot;http://amzn.com/B001C8VA26&quot;&gt;novel&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;At my first real programming job, I started out coding in Actionscript
2.0 but when a particular developer left the company, someone was
needed to take over server-side development in PHP, so I took it upon
myself to learn PHP, and, as it turned out, also ended up needing to
learn SQL and relational databases. I read a PHP book or two and a
whole lot of blogs, but mostly just dove right in to the existing code
and gradually made sense out of it. Eventually I was working back and
forth between Actionscript and PHP pretty regularly. That kind of
pick-it-up-as-needed approach is pretty much how I roll, though it’s
hard to explain this kind of adaptability to recruiters who are
looking to basically keyword-match your experience against a job
description, which can be a real drag if you’re the type of person who
craves new experiences. When at UNI I had been the kind of student
that made a point of taking the more theoretical computer-sciencey
courses, on the rationale that things like programming languages are
certain to change in the future, but they will most likely continue to
build on the same underlying theory dating at last as far back as good
ol’ Alan Turing. I would say that approach has paid off well for me in
the years since. My first boss described me in a LinkedIn endorsement
as being capable of working in multiple programming languages
simultaneously, “something which drives most of us insane.”&lt;/p&gt;

&lt;p&gt;But I digress (often). Like I said starting out this post, sometimes I
still surprise myself. When I pull off something new or just more
complex than I’m used to, it feels good, and I like to share it, not
just to strut about, but also because I am sure others are out there
trying to solve similar problems, and also to give credit to others
whose work I drew on to arrive at my solution. And like I said, my SQL
skills are largely the product of a few old blog posts and experience
so I was pretty stoked at what I pulled off this week.&lt;/p&gt;

&lt;h2 id=&quot;the-assignment&quot;&gt;The assignment&lt;/h2&gt;

&lt;p&gt;I was given the task of populating a “related articles” part of a page
on a news website. Naturally the first thing I thought we needed to
hash out was how the system should conclude that two articles are
related. After some discussion we arrived at this idea: we would score
two articles’ relatedness based on:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The number of keyword tags they have in common (this was the same
site using &lt;a href=&quot;https://github.com/mbleigh/acts-as-taggable-on&quot;&gt;acts_as_taggable_on&lt;/a&gt; from which I drew
&lt;a href=&quot;/2013/11/09/acts_as_taggable_on_active_admin_select2.html&quot;&gt;this recent post&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;The number of retailers they have in common (Article HABTM
Retailer)&lt;/li&gt;
  &lt;li&gt;How close or far apart their &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;published_at&lt;/code&gt; timestamps are (in
months)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-this-turns-out-to-be-slightly-difficult&quot;&gt;How this turns out to be slightly difficult&lt;/h2&gt;

&lt;p&gt;This sounds perfectly reasonable, even like it would be pretty easy to
express in an OO/procedural kind of way in Ruby or any other
mainstream programming language. But once this site gets a long
history of articles, it’s likely that looping or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#map&lt;/code&gt;ing through all
of them to work this out is going to get way too time and memory
intensive to keep the site running responsively.&lt;/p&gt;

&lt;p&gt;Another alternative is to store relatedness scores in a database table
and update them only when they need to change; we could hook in to
Rails’s lifecycle callbacks like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;after_save&lt;/code&gt; so that when an article is
created or saved, we insert or update a record for its relatedness to
every other article. That still sounds intensive but we could at least
kick off a background worker to handle it. However, I got the feeling
that there was potential for errors caused by overlooking some event
that would warrant recalculating this table, or missing some pairs.&lt;/p&gt;

&lt;p&gt;And there was still another wrinkle to work out: the relatedness
scores pertain to pairs of articles, and those pairs should be
considered un-ordered: the concept of article A’s relatedness to
article B is identical to B’s relatedness to A. I don’t know if any
databases have an unordered tuple data type and even if they did
whether ActiveRecord would know how to use it. It seems wasteful and
error-prone to maintain redundant records so as to have the pairings
both ways around. Googling about for good ways to represent a
symmetrical matrix in a SQL database didn’t bear much fruit. So it
would probably be best to enforce an ordering (“always put the article
with the lower ID first” seems reasonable). But then this means to
look up related articles, we need to find the current article’s ID in
one of &lt;em&gt;two&lt;/em&gt; association columns, rather than just one, and then use
the &lt;em&gt;other&lt;/em&gt; column to find the related article. I’m pretty sure
ActiveRecord doesn’t have a way to express this kind of thing as an
association. Which is too bad, because ideally, if possible, we’d like
to get the relatedness scores and related articles in the form of a
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Relation&lt;/code&gt; so that we can chain other operations like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#limit&lt;/code&gt; or
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#order&lt;/code&gt; onto it. (Possibly we could write it as a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scope&lt;/code&gt; with a
lambda and give the model a method that passes &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;self.id&lt;/code&gt; to that, but
I’m still not sure we would get a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Relation&lt;/code&gt; rather than an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Array&lt;/code&gt;.
The point at which ActiveRecord’s magic decides to convert from one to
the other is something I find myself constantly guessing on, guessing
wrong, and getting confused and annoyed trying to come up with a
workaround.) But so it goes.&lt;/p&gt;

&lt;p&gt;Any way we look at this, it looks like we’re going to be stuck writing
some pretty serious SQL “by hand”.&lt;/p&gt;

&lt;p&gt;I’m not going to show my whole solution here, but you probably don’t
need all of it anyway. I think the most useful bit of it to share is
the shared-tags calculation.&lt;/p&gt;

&lt;h2 id=&quot;counting-shared-tags-in-sql&quot;&gt;Counting shared tags in SQL&lt;/h2&gt;

&lt;p&gt;acts_as_taggable_on has some methods for matching any (or all) of
the tags on a list, and versions of this that are aware of tag
contexts (the gem supports giving things different kinds/contexts of
tags, which I’m not going into here but it’s a cool feature). So
obviously you can call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#tagged_with&lt;/code&gt; using an Article’s tag list to
get Articles that share tags with it, but the documentation doesn’t
mention anything about ordering the results according to how many tags
are matched, or even finding out that number. Well, here’s the SQL
query I arrived at that uses acts_as_taggable_on’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;taggings&lt;/code&gt; table
to build a list of article pairs and counts of their shared tags. One
nifty thing about it is that it involves joining a table to itself. To
do this, you have to alias the tables so that you can specify which
side of the join you mean when specifying columns, otherwise you’ll
either get an ambiguous column name error or you’ll just get confused.
You’ll see I’ve also added a condition in the join that the “first” id
be lower than the “second,” forcing an ordering to the ID pairs so as
to eliminate duplicate/reversed-order rows and also eliminate
comparing any article with itself, since we don’t care to consider an
article related to itself. (Also, the way this is written Article
pairings with no shared tags won’t be returned at all. Maybe try a
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left join&lt;/code&gt; if you want that.)&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot; data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;taggable_id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_article_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;taggable_id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;second_article_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shared_tags&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;taggings&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;taggings&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;second&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;on&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag_id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;taggable_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;taggable_type&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;taggable_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;taggable_id&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;taggable_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Article'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_article_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;second_article_id&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Add a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;and first_article_id = 23 or second_article_id = 23&lt;/code&gt; to the
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;where&lt;/code&gt; clause here and you’ll get just the rows pertaining to article&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Add an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;order by shared_tags desc&lt;/code&gt; and the rows will come back
with the highest shared-tag-counts, the “most related,” at the top. If
you’re looking to know the number of shared acts_as_taggable_on
tags among your articles or whatever other model you have, here you
are.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;building-a-leaning-tower-of-sql&quot;&gt;Building a leaning tower of SQL&lt;/h2&gt;

&lt;p&gt;So, for the other two relatedness factors, I did a similar query to
this against the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;articles_retailers&lt;/code&gt; table to count shared retailers,
and another on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;articles&lt;/code&gt; to compute the number of months apart that
pairs of articles were published to the site. Each query used the same
“first id less than second id” constraint. Then I pulled the three
queries together as subqueries of one larger query, joining them by
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;first_article_id&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;second_article_id&lt;/code&gt;, and added a calculated
column whose value was the shared tags count plus the shared retailers
count minus the months-apart count and call this their &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;score&lt;/code&gt; – a
heuristic, arbitrary measure of “how related” each pairing of articles
is. (The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coalesce&lt;/code&gt; function came in mighty handy here. Despite its
esoteric-sounding name, all it does is exchange a null value for
something else you specify, like you might do with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;||&lt;/code&gt; in Ruby – so
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coalesce(shared_tags, 0)&lt;/code&gt; returns 0 if &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;shared_tags&lt;/code&gt; is null, or
otherwise returns whatever &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;shared_tags&lt;/code&gt; is, for example.)&lt;/p&gt;

&lt;p&gt;As you are probably picturing in your head, the resulting master
relatedness-score query is &lt;em&gt;huge&lt;/em&gt;. It took me a good couple hours at a
MySQL command-line prompt composing the subqueries and overall query a
little bit at a time. It felt &lt;em&gt;awesome&lt;/em&gt;. But still: the result was one
seriously big glob of SQL. (Incidentally iTerm2 acted up in a &lt;em&gt;really&lt;/em&gt;
weird way when I tried pasting these large blocks of code into it, but
not when I was SSHed into a remote server; if this rings a bell to
you, drop me a line.) I’m going to spare you the eye-bleeding caused
by seeing the whole thing. You’re going to drop &lt;em&gt;that&lt;/em&gt; big nasty thing
in the middle of some ActiveRecord model? Yikes!&lt;/p&gt;

&lt;h2 id=&quot;views-to-the-rescue&quot;&gt;Views to the rescue&lt;/h2&gt;

&lt;p&gt;In a forum thread where I was looking for help on the implementation
of all this, &lt;a href=&quot;http://rietta.com/&quot;&gt;Frank Rietta&lt;/a&gt; suggested I consider using a
database view. To be perfectly honest, I hadn’t used a view in years,
if ever. I didn’t even think MySQL had them (yes, I’m using MySQL,
don’t judge) – maybe some older version I used in the past didn’t and
they’ve been added since? At first I wasn’t sure how this could help
me, but then Frank wrote &lt;a href=&quot;http://blog.rietta.com/blog/2013/11/28/rails-and-sql-views-for-a-report/&quot;&gt;this excellent blog post&lt;/a&gt;
on the subject. I read it, and the more I thought about it, the better
the idea sounded.&lt;/p&gt;

&lt;p&gt;Basically, a view acts like a regular database table, at least when it
comes to querying it with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;select&lt;/code&gt;. But underneath it’s based on
some query you come up with of other tables and views. You can’t write
to it, but it provides you with a different “view” of your data by
what I would describe as “abstracting a query.” And because the view
can be read from like any other table, it can also act as the table
behind an ActiveRecord model (at least, until you try to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#save&lt;/code&gt; to
it). Go read &lt;a href=&quot;http://blog.rietta.com/blog/2013/11/28/rails-and-sql-views-for-a-report/&quot;&gt;Frank’s post&lt;/a&gt; so I don’t have to recap
it here. You’ll be glad you did.&lt;/p&gt;

&lt;p&gt;The great advantage of using a view to hold the relatedness scoring is
that I don’t have to think about writing Ruby code to maintain the
table of relatedness scores, I don’t have to think about background
jobs or hooking into ActiveRecord lifecycle callbacks to maintain the
data or any of that – the database itself keeps this “table” updated.
Any time the tables it depends on change, it changes right along with
them automatically. Plus it gets the big hairy SQL query out of my
Ruby code where it won’t distract or confuse anyone; and it handles
the issue of making sure &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;first_article_id&lt;/code&gt; is always lower than
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;second_article_id&lt;/code&gt; because that’s expressed right in the query it’s
based on.&lt;/p&gt;

&lt;p&gt;So that settles it, I create a view out of my big relatedness-scoring
query and an ActiveRecord model over top of it! Only one problem, and
it turned out to be pretty minor, but as I mentioned, my big
relatedness query involved a join over three subqueries. Turns out
that in MySQL, views can’t have subqueries. Perhaps they can in other
database engines, I would not be surprised, but not in MySQL. The
workaround for this is to create views for the subqueries and query
those views. Honestly that probably makes the SQL read more easily
anyway. On the other hand, I ended up creating four views. That was
definitely the longest Rails migration I have ever written, by far.&lt;/p&gt;

&lt;h2 id=&quot;the-models-and-other-miscellaneous-thoughts&quot;&gt;The models and other miscellaneous thoughts&lt;/h2&gt;

&lt;p&gt;So, now I have a table called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;article_relations&lt;/code&gt; that contains pairs
of Article id’s and their relatedness scores, I can give it a model
like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ArticleRelation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ActiveRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Base&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;belongs_to&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:first_article&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;ss&quot;&gt;class_name: &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Article'&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;belongs_to&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:second_article&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;class_name: &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Article'&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;other_article&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_article&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;second_article&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;readonly?&lt;/span&gt;
    &lt;span class=&quot;kp&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;And give the Article model a couple methods like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;article_relations&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;ArticleRelation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;s1&quot;&gt;'first_article_id = ? or second_article_id = ?'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'score desc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;related_articles&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;article_relations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;other_article&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Or something to this effect. You’ll likely want to have your view only
contain records where the score is above 0, for instance, or give the
above methods an optional parameter to use in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;limit&lt;/code&gt; so you can
limit the number of related articles you show.&lt;/p&gt;

&lt;p&gt;Which reminds me, speaking of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#limit&lt;/code&gt;… as I alluded to before, it
would be great if I could do things like
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@article.related_articles.limit(10)&lt;/code&gt; here but I can’t. This bugs me a
little bit, because it means that some of my queries to the Article
class are going to call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#limit&lt;/code&gt; and others will have to pass the
limit as a parameter, or slice the array like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[0..9]&lt;/code&gt; or something,
so I have code where doing the “same” thing reads completely
differently. (I am also unfortunate enough to still be working with
Rails 2 regularly, where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;limit&lt;/code&gt; goes in an options hash. It appears
if you try that syntax in Rails 3, it just ignores it.) There are
other gems like &lt;a href=&quot;https://github.com/biola/punching_bag&quot;&gt;punching_bag&lt;/a&gt; where this itches
at me a little as well (not to mention, I’d like to be able to give my
model a method or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scope&lt;/code&gt; with a name more appropriate to my domain
such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;popular&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hot&lt;/code&gt; and have that delegate to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;most_hit&lt;/code&gt;). I
think this might just be a product of the usual leakiness of ORM
abstractions and I’ll just have to get over it.&lt;/p&gt;

&lt;p&gt;One caveat that should be pointed out is that Rails’s generating of
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schema.rb&lt;/code&gt; doesn’t handle views “properly” and probably can’t be made
to when you think about it or depending on what you think the proper
thing for it to do would be. Rails will dump the structure of your
views out as regular tables, so if you use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rake db:schema:load&lt;/code&gt;
you’ll get tables rather than views with all their cool magic. At this
point it’s probably a good idea to uncomment that
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;config.active_record.schema_format = :sql&lt;/code&gt; line in your
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;application.rb&lt;/code&gt; configuration file, which will make &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rake db:migrate&lt;/code&gt;
spit out a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;structure.sql&lt;/code&gt; file instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schema.rb&lt;/code&gt;, and get rid of
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schema.rb&lt;/code&gt; altogether.&lt;/p&gt;

&lt;p&gt;Another thing worth considering, depending on the complexity of your
view(s), is whether to make them
&lt;a href=&quot;https://en.wikipedia.org/wiki/Materialized_view&quot;&gt;materialized views&lt;/a&gt;. This is a view that’s
backed by a physical table that gets updated as needed. It’s more
efficient to query but a little slower to update so the effects of a
change to one of the tables it depends on might not be reflected right
away, but this may be a worthwhile trade-off to make.&lt;/p&gt;

&lt;p&gt;Join me next time when I talk about technical debt or something like
that.&lt;/p&gt;</content><author><name></name></author><category term="rails" /><category term="ruby" /><category term="sql" /><summary type="html">Occasionally I surprise myself and end up feeling a desire to write about it and toot my own horn a little bit. What better place to do that than on a professional blog at least part of the purpose of which is to show prospective employers or clients that I’m good at stuff? I’m pretty good, I guess note: personal background jabber, skip this section at will I’m largely self-taught in the area of databases and SQL. The only course I ever took on the subject was a quarter-length database class, circa 1999, at Hamilton College (since bought up by Kaplan, I think) as part of their two-year IT degree program. It used Microsoft Access and was very beginner-level and I think I might have been out sick on joins day. Later when pursuing my Computer Science degree I avoided the databases course out of dislike for the professor who taught it; the alternative course to meet the same requirement had more to do with text indexing, information theory – search-engine kind of stuff – and oddly enough, the course taught and used an open-source multi-dimensional hierarchical database and MUMPS compiler developed by the course’s professor (multi-dimensional databases are quite good at storing and comparing things like, vectors of the occurrences of hundreds of different words in a bunch of textual articles). So, yes, I learned MUMPS in college instead of SQL. Actually, you can download and make-install the C++ code for the MUMPS compiler we used yourself, which compiles MUMPS into C++, if you ever get a wild urge to do such a thing. In fact, I’d recommend it to my fellow programming language nerds, especially those interested in old, obscure, or just plain weird languages. At the very least you’ll have a little fun with it; and I believe MUMPS is even still in use in some corners of the health care industry, so you’d be picking up a skill that’s in some demand yet increasingly difficult to hire for. (While you’re at it, check out Dr. O’Kane’s MUMPS book and his rollicking, action-packed novel.) At my first real programming job, I started out coding in Actionscript 2.0 but when a particular developer left the company, someone was needed to take over server-side development in PHP, so I took it upon myself to learn PHP, and, as it turned out, also ended up needing to learn SQL and relational databases. I read a PHP book or two and a whole lot of blogs, but mostly just dove right in to the existing code and gradually made sense out of it. Eventually I was working back and forth between Actionscript and PHP pretty regularly. That kind of pick-it-up-as-needed approach is pretty much how I roll, though it’s hard to explain this kind of adaptability to recruiters who are looking to basically keyword-match your experience against a job description, which can be a real drag if you’re the type of person who craves new experiences. When at UNI I had been the kind of student that made a point of taking the more theoretical computer-sciencey courses, on the rationale that things like programming languages are certain to change in the future, but they will most likely continue to build on the same underlying theory dating at last as far back as good ol’ Alan Turing. I would say that approach has paid off well for me in the years since. My first boss described me in a LinkedIn endorsement as being capable of working in multiple programming languages simultaneously, “something which drives most of us insane.” But I digress (often). Like I said starting out this post, sometimes I still surprise myself. When I pull off something new or just more complex than I’m used to, it feels good, and I like to share it, not just to strut about, but also because I am sure others are out there trying to solve similar problems, and also to give credit to others whose work I drew on to arrive at my solution. And like I said, my SQL skills are largely the product of a few old blog posts and experience so I was pretty stoked at what I pulled off this week. The assignment I was given the task of populating a “related articles” part of a page on a news website. Naturally the first thing I thought we needed to hash out was how the system should conclude that two articles are related. After some discussion we arrived at this idea: we would score two articles’ relatedness based on: The number of keyword tags they have in common (this was the same site using acts_as_taggable_on from which I drew this recent post) The number of retailers they have in common (Article HABTM Retailer) How close or far apart their published_at timestamps are (in months) How this turns out to be slightly difficult This sounds perfectly reasonable, even like it would be pretty easy to express in an OO/procedural kind of way in Ruby or any other mainstream programming language. But once this site gets a long history of articles, it’s likely that looping or #maping through all of them to work this out is going to get way too time and memory intensive to keep the site running responsively. Another alternative is to store relatedness scores in a database table and update them only when they need to change; we could hook in to Rails’s lifecycle callbacks like after_save so that when an article is created or saved, we insert or update a record for its relatedness to every other article. That still sounds intensive but we could at least kick off a background worker to handle it. However, I got the feeling that there was potential for errors caused by overlooking some event that would warrant recalculating this table, or missing some pairs. And there was still another wrinkle to work out: the relatedness scores pertain to pairs of articles, and those pairs should be considered un-ordered: the concept of article A’s relatedness to article B is identical to B’s relatedness to A. I don’t know if any databases have an unordered tuple data type and even if they did whether ActiveRecord would know how to use it. It seems wasteful and error-prone to maintain redundant records so as to have the pairings both ways around. Googling about for good ways to represent a symmetrical matrix in a SQL database didn’t bear much fruit. So it would probably be best to enforce an ordering (“always put the article with the lower ID first” seems reasonable). But then this means to look up related articles, we need to find the current article’s ID in one of two association columns, rather than just one, and then use the other column to find the related article. I’m pretty sure ActiveRecord doesn’t have a way to express this kind of thing as an association. Which is too bad, because ideally, if possible, we’d like to get the relatedness scores and related articles in the form of a Relation so that we can chain other operations like #limit or #order onto it. (Possibly we could write it as a scope with a lambda and give the model a method that passes self.id to that, but I’m still not sure we would get a Relation rather than an Array. The point at which ActiveRecord’s magic decides to convert from one to the other is something I find myself constantly guessing on, guessing wrong, and getting confused and annoyed trying to come up with a workaround.) But so it goes. Any way we look at this, it looks like we’re going to be stuck writing some pretty serious SQL “by hand”. I’m not going to show my whole solution here, but you probably don’t need all of it anyway. I think the most useful bit of it to share is the shared-tags calculation. Counting shared tags in SQL acts_as_taggable_on has some methods for matching any (or all) of the tags on a list, and versions of this that are aware of tag contexts (the gem supports giving things different kinds/contexts of tags, which I’m not going into here but it’s a cool feature). So obviously you can call #tagged_with using an Article’s tag list to get Articles that share tags with it, but the documentation doesn’t mention anything about ordering the results according to how many tags are matched, or even finding out that number. Well, here’s the SQL query I arrived at that uses acts_as_taggable_on’s taggings table to build a list of article pairs and counts of their shared tags. One nifty thing about it is that it involves joining a table to itself. To do this, you have to alias the tables so that you can specify which side of the join you mean when specifying columns, otherwise you’ll either get an ambiguous column name error or you’ll just get confused. You’ll see I’ve also added a condition in the join that the “first” id be lower than the “second,” forcing an ordering to the ID pairs so as to eliminate duplicate/reversed-order rows and also eliminate comparing any article with itself, since we don’t care to consider an article related to itself. (Also, the way this is written Article pairings with no shared tags won’t be returned at all. Maybe try a left join if you want that.) select first.taggable_id as first_article_id, second.taggable_id as second_article_id, count(first.tag_id) as shared_tags from taggings as first join taggings as second on first.tag_id = second.tag_id and first.taggable_type = second.taggable_type and first.taggable_id &amp;lt; second.taggable_id where first.taggable_type = 'Article' group by first_article_id, second_article_id Add a and first_article_id = 23 or second_article_id = 23 to the where clause here and you’ll get just the rows pertaining to article Add an order by shared_tags desc and the rows will come back with the highest shared-tag-counts, the “most related,” at the top. If you’re looking to know the number of shared acts_as_taggable_on tags among your articles or whatever other model you have, here you are. Building a leaning tower of SQL So, for the other two relatedness factors, I did a similar query to this against the articles_retailers table to count shared retailers, and another on articles to compute the number of months apart that pairs of articles were published to the site. Each query used the same “first id less than second id” constraint. Then I pulled the three queries together as subqueries of one larger query, joining them by first_article_id and second_article_id, and added a calculated column whose value was the shared tags count plus the shared retailers count minus the months-apart count and call this their score – a heuristic, arbitrary measure of “how related” each pairing of articles is. (The coalesce function came in mighty handy here. Despite its esoteric-sounding name, all it does is exchange a null value for something else you specify, like you might do with || in Ruby – so coalesce(shared_tags, 0) returns 0 if shared_tags is null, or otherwise returns whatever shared_tags is, for example.) As you are probably picturing in your head, the resulting master relatedness-score query is huge. It took me a good couple hours at a MySQL command-line prompt composing the subqueries and overall query a little bit at a time. It felt awesome. But still: the result was one seriously big glob of SQL. (Incidentally iTerm2 acted up in a really weird way when I tried pasting these large blocks of code into it, but not when I was SSHed into a remote server; if this rings a bell to you, drop me a line.) I’m going to spare you the eye-bleeding caused by seeing the whole thing. You’re going to drop that big nasty thing in the middle of some ActiveRecord model? Yikes! Views to the rescue In a forum thread where I was looking for help on the implementation of all this, Frank Rietta suggested I consider using a database view. To be perfectly honest, I hadn’t used a view in years, if ever. I didn’t even think MySQL had them (yes, I’m using MySQL, don’t judge) – maybe some older version I used in the past didn’t and they’ve been added since? At first I wasn’t sure how this could help me, but then Frank wrote this excellent blog post on the subject. I read it, and the more I thought about it, the better the idea sounded. Basically, a view acts like a regular database table, at least when it comes to querying it with a select. But underneath it’s based on some query you come up with of other tables and views. You can’t write to it, but it provides you with a different “view” of your data by what I would describe as “abstracting a query.” And because the view can be read from like any other table, it can also act as the table behind an ActiveRecord model (at least, until you try to #save to it). Go read Frank’s post so I don’t have to recap it here. You’ll be glad you did. The great advantage of using a view to hold the relatedness scoring is that I don’t have to think about writing Ruby code to maintain the table of relatedness scores, I don’t have to think about background jobs or hooking into ActiveRecord lifecycle callbacks to maintain the data or any of that – the database itself keeps this “table” updated. Any time the tables it depends on change, it changes right along with them automatically. Plus it gets the big hairy SQL query out of my Ruby code where it won’t distract or confuse anyone; and it handles the issue of making sure first_article_id is always lower than second_article_id because that’s expressed right in the query it’s based on. So that settles it, I create a view out of my big relatedness-scoring query and an ActiveRecord model over top of it! Only one problem, and it turned out to be pretty minor, but as I mentioned, my big relatedness query involved a join over three subqueries. Turns out that in MySQL, views can’t have subqueries. Perhaps they can in other database engines, I would not be surprised, but not in MySQL. The workaround for this is to create views for the subqueries and query those views. Honestly that probably makes the SQL read more easily anyway. On the other hand, I ended up creating four views. That was definitely the longest Rails migration I have ever written, by far. The models and other miscellaneous thoughts So, now I have a table called article_relations that contains pairs of Article id’s and their relatedness scores, I can give it a model like this: class ArticleRelation &amp;lt; ActiveRecord::Base belongs_to :first_article, class_name: 'Article' belongs_to :second_article, class_name: 'Article' def other_article(source) [first_article, second_article].find{|a| a != source} end def readonly? true end end And give the Article model a couple methods like this: def article_relations ArticleRelation.where( 'first_article_id = ? or second_article_id = ?', id, id).order('score desc') end def related_articles article_relations.map{|r| r.other_article(self)} end Or something to this effect. You’ll likely want to have your view only contain records where the score is above 0, for instance, or give the above methods an optional parameter to use in a limit so you can limit the number of related articles you show. Which reminds me, speaking of #limit… as I alluded to before, it would be great if I could do things like @article.related_articles.limit(10) here but I can’t. This bugs me a little bit, because it means that some of my queries to the Article class are going to call #limit and others will have to pass the limit as a parameter, or slice the array like [0..9] or something, so I have code where doing the “same” thing reads completely differently. (I am also unfortunate enough to still be working with Rails 2 regularly, where limit goes in an options hash. It appears if you try that syntax in Rails 3, it just ignores it.) There are other gems like punching_bag where this itches at me a little as well (not to mention, I’d like to be able to give my model a method or scope with a name more appropriate to my domain such as popular or hot and have that delegate to most_hit). I think this might just be a product of the usual leakiness of ORM abstractions and I’ll just have to get over it. One caveat that should be pointed out is that Rails’s generating of schema.rb doesn’t handle views “properly” and probably can’t be made to when you think about it or depending on what you think the proper thing for it to do would be. Rails will dump the structure of your views out as regular tables, so if you use rake db:schema:load you’ll get tables rather than views with all their cool magic. At this point it’s probably a good idea to uncomment that config.active_record.schema_format = :sql line in your application.rb configuration file, which will make rake db:migrate spit out a structure.sql file instead of schema.rb, and get rid of schema.rb altogether. Another thing worth considering, depending on the complexity of your view(s), is whether to make them materialized views. This is a view that’s backed by a physical table that gets updated as needed. It’s more efficient to query but a little slower to update so the effects of a change to one of the tables it depends on might not be reflected right away, but this may be a worthwhile trade-off to make. Join me next time when I talk about technical debt or something like that.</summary></entry></feed>